{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ANMNCPOP_Real_Data_Standardization\n",
        "Welcome to the example for real data standardization in causal discovery!\n",
        "\n",
        "For further analysis, all useful infomation is extracted and saved as .npz file.\n",
        "\n",
        "# Input Data Form:\n",
        "The data can be any format that is supported by the Real_Data_Standardization() function, currently including npy, tar.gz, csv and tsv.\n",
        "\n",
        "**Two Dimensions Causality Data:**\n",
        "* **npz file**\n",
        "\n",
        "Storing causality Data as NumPy array x and y under a npz file.\n",
        "\n",
        "* **tar.gz file**\n",
        "\n",
        "Archiving and compressing causality files and folders as a tar.gz file.\n",
        "\n",
        "* **csv files**\n",
        "\n",
        "Raw data and casaul matrix are saved as separate csv files.\n",
        "\n",
        "**Multiple Features Time Series:**\n",
        "* **tsv files**\n",
        "\n",
        "Single sample trajectory with multiple features Time Series as shape of (F features, T timeSets) - incluing S smples, i.e. S number of .tsv files\n",
        "\n",
        "# Standardization process:\n",
        "* Causality Data stored as NumPy array B and XX under a npz file.\n",
        "* For multiple features time series data, all time series will be saved as a (Feature_num, Sample_num, Time) three dimensions array for applying ANM-NCPOP.\n",
        "\n",
        "# Output Data Form\n",
        "* **Raw_data:**\n",
        "\n",
        "An array saves F features, S smples and T timesets Time Series.\n",
        "\n",
        "* **True_dag:**\n",
        "\n",
        "A causal matrix is saved as shape of (F features, F features)\n",
        "\n",
        "Learned underlying causal relationships between obeservations, according to expert experience or ground true causality.\n",
        "\n",
        "# Example\n",
        "In our example, multiple features time series are saved under Krebs_Cycle.npz as a casaul matrix and an array, separately.\n",
        "\n",
        "* __x__: is an array in shape(F, S, T), where the number of row F is features_num, the number of column S is smples_num and the number of deep T is timesets.\n",
        "* __y__: is a nonsymmetric square matrix.\n"
      ],
      "metadata": {
        "id": "kq1OSo5X0whe"
      },
      "id": "kq1OSo5X0whe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_zr02dCTVJ"
      },
      "source": [
        "#__Step 1: Get start__\n",
        "\n",
        "\n",
        "* mount drive\n",
        "* set envirment\n",
        "* install packages"
      ],
      "id": "Po_zr02dCTVJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHf74wQIVx2v",
        "outputId": "5c4a72bc-10c6-4db3-fed4-a9157114da8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\")\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/Details_Krebs_Cycle/MetricsDAG/\")\n"
      ],
      "id": "oHf74wQIVx2v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 2: Standardized Data class__"
      ],
      "metadata": {
        "id": "vK-ciKBQTALM"
      },
      "id": "vK-ciKBQTALM"
    },
    {
      "cell_type": "code",
      "source": [
        "# from Data_Standardization import*\n",
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "\n",
        "class Real_Data_Standardization(object):\n",
        "    '''\n",
        "    A class for preparing data to simulate random (causal) DAG.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    File_PATH: str\n",
        "        Save file path\n",
        "    File_NAME: str\n",
        "        Read data name\n",
        "    '''\n",
        "\n",
        "    def __init__(self, File_PATH, Data_NAME):\n",
        "        self.File_PATH = File_PATH\n",
        "        self.Data_NAME = Data_NAME\n",
        "\n",
        "    def Produce_Rawdata(self):\n",
        "\n",
        "        def readable_File(FilePATH):\n",
        "            read_Dir=os.listdir(FilePATH)\n",
        "            count = 0\n",
        "            readable_F = []\n",
        "            for f in read_Dir:\n",
        "                file = os.path.join(FilePATH, f)\n",
        "                if os.path.isdir(file):\n",
        "                    count = count+1\n",
        "                else:\n",
        "                    readable_F.append(f)\n",
        "            return count,readable_F\n",
        "\n",
        "        self.Read_File = readable_File(self.File_PATH)[1]\n",
        "        self.TS_path = self.File_PATH + self.Data_NAME + '_TS/'\n",
        "\n",
        "        # Check empty files under riute\n",
        "        if len(self.File_PATH) == 0:\n",
        "            print('INFO: No Data Under the Current Route!')\n",
        "        else:\n",
        "            File_NAME = []\n",
        "            File_TYPE = []\n",
        "\n",
        "            # Delete files and list readable Files\n",
        "            for i in self.Read_File:\n",
        "                File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "                File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "            ###################################### Deal with Two Dimensions Causality Data ###################################\n",
        "            if self.Data_NAME+'.npz' in self.Read_File:\n",
        "                Tests_data = np.load(self.File_PATH + self.Data_NAME+'.npz', allow_pickle=True)\n",
        "                Raw_data = Tests_data['x']\n",
        "                true_dag = Tests_data['y']\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            elif self.Data_NAME+'.tar.gz' in self.Read_File:\n",
        "                # open file\n",
        "                file = tarfile.open(self.File_PATH + self.Data_NAME + '.tar.gz')\n",
        "\n",
        "                # print file names\n",
        "                file_names = file.getnames()\n",
        "                print(file_names)\n",
        "\n",
        "                # extract files\n",
        "                file.extractall(self.File_PATH)\n",
        "\n",
        "                # close file\n",
        "                file.close()\n",
        "\n",
        "                Raw_data = pd.read_csv(self.File_PATH+file_names[1])\n",
        "                true_dag = np.load(self.File_PATH+file_names[2])\n",
        "\n",
        "                # save numpy to npz file\n",
        "                np.savez(self.File_PATH + self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            elif self.Data_NAME+'.csv' in self.Read_File:\n",
        "                Raw_data = pd.read_csv(self.File_PATH+ self.Data_NAME+'.csv', header=0, index_col=0)\n",
        "                true_dag = pd.read_csv(self.File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "\n",
        "                # save numpy to npz file\n",
        "                np.savez(self.File_PATH + self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            ################################ Deal with Multi-dimensions Causality Data ###################################\n",
        "            elif os.path.exists(self.TS_path):\n",
        "                read_Dir_TS=os.listdir(self.TS_path)\n",
        "                Timeseries_List_path = self.File_PATH+'series_list.csv'\n",
        "                Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "                # print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "                if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "                    print('INFO: Start Analyzing '+ self.Data_NAME + ' Time Series File!')\n",
        "                    TS_List = read_Dir_TS\n",
        "                else:\n",
        "                    print('INFO: Start Analyzing '+ self.Data_NAME + ' Time Series List!')\n",
        "                    TS_List = Read_Timeseries['Series_num']\n",
        "                lds = pd.read_csv(self.TS_path+ TS_List[0], delimiter='\\t', index_col=0, header=None)\n",
        "                # print(lds)\n",
        "                n = len(TS_List)\n",
        "                T = lds.shape[1]\n",
        "                # d = lds.shape[0]\n",
        "                # print(d, T, n)\n",
        "                df = np.transpose(lds)\n",
        "                feature_name = df.columns\n",
        "                d = len(feature_name)\n",
        "                Raw_data = np.zeros((d, n, T))\n",
        "                for ns in range(n):\n",
        "                    X = pd.read_csv(self.TS_path+ TS_List[ns], delimiter='\\t', index_col=0, header=None)\n",
        "                    df = np.transpose(X)\n",
        "                    feature_name = df.columns\n",
        "                    for fn in range(d):\n",
        "                        Raw_data[fn, ns, :] = list(df[feature_name[fn]])\n",
        "                # print(Raw_data.shape)\n",
        "                # save numpy to npz file\n",
        "                matrix = np.zeros((d, d))\n",
        "                np.fill_diagonal(matrix, 0)\n",
        "                np.fill_diagonal(matrix[:, 1:], 1)\n",
        "                np.savez(self.File_PATH + self.Data_NAME+'.npz', x=Raw_data , y=matrix)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            else:\n",
        "                print('INFO: Wrong DataType!')\n",
        ""
      ],
      "metadata": {
        "id": "E7Y5FRv8QyUD"
      },
      "id": "E7Y5FRv8QyUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 3: Test__"
      ],
      "metadata": {
        "id": "u_4vgMBI1eFQ"
      },
      "id": "u_4vgMBI1eFQ"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ############################################################################################################\n",
        "    ############################################ SETTING File_PATH and file_name ###############################\n",
        "    ############################################################################################################\n",
        "\n",
        "    File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "    file_name = 'Krebs_Cycle'\n",
        "    dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "    dt.Produce_Rawdata()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ai2O_kDa23fJ",
        "outputId": "c156b38e-03d2-4288-b4f7-cab7075cf535"
      },
      "id": "ai2O_kDa23fJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ANMPOP_ReadData.Produce_Rawdata() missing 1 required positional argument: 'self'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2fb461538787>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linearGauss_6_15'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANMPOP_ReadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFile_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProduce_Rawdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: ANMPOP_ReadData.Produce_Rawdata() missing 1 required positional argument: 'self'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test  Two Dimensions Causality Data\n",
        "if __name__ == \"__main__\":\n",
        "    ############################################################################################################\n",
        "    ############################################ SETTING File_PATH and file_name ###############################\n",
        "    ############################################################################################################\n",
        "\n",
        "    File_PATH = \"./Test_Datasets/Real_data/\"\n",
        "    file_name = 'linearGauss_6_15'\n",
        "    dt = ANMPOP_ReadData(File_PATH, file_name)\n",
        "    dt.Produce_Rawdata()\n",
        "\n",
        "# Test Three Dimensions Causality Time Series Data\n",
        "if __name__ == \"__main__\":\n",
        "    ############################################################################################################\n",
        "    ############################################ SETTING File_PATH and file_name ###############################\n",
        "    ############################################################################################################\n",
        "\n",
        "    File_PATH = \"./Test_Datasets/Real_data/\"\n",
        "    file_name = 'Krebs_Cycle'\n",
        "    dt = ANMPOP_ReadData(File_PATH, file_name)\n",
        "    dt.Produce_Rawdata()"
      ],
      "metadata": {
        "id": "QAhoM6ZW3gDh"
      },
      "id": "QAhoM6ZW3gDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "i9WfAVotsbxZ"
      },
      "id": "i9WfAVotsbxZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Debug class"
      ],
      "metadata": {
        "id": "5AZGUtcqX1aF"
      },
      "id": "5AZGUtcqX1aF"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "from itertools import combinations\n",
        "from pickle import TRUE\n",
        "\n",
        "File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "os.chdir(File_PATH)\n",
        "read_Dir=os.listdir(File_PATH)\n",
        "Data_NAME = 'Krebs_Cycle'\n",
        "Readable_File = readable_File(File_PATH)[1]\n",
        "num_readable_File = len(read_Dir) - readable_File(File_PATH)[0]\n",
        "TS_path = File_PATH+Data_NAME+'_TS/'\n",
        "\n",
        "def readable_File(path):\n",
        "    read_Dir=os.listdir(path)\n",
        "    count = 0\n",
        "    readable_File = []\n",
        "    for f in read_Dir:\n",
        "      file = os.path.join(path, f)\n",
        "      if os.path.isdir(file):\n",
        "        count = count+1\n",
        "      else:\n",
        "        readable_File.append(f)\n",
        "    return count,readable_File\n",
        "\n",
        "read_Dir_TS=os.listdir(TS_path)\n",
        "Timeseries_List_path = File_PATH+'series_list.csv'\n",
        "Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "# print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "  print('INFO: Start Analyzing '+ Data_NAME + ' Time Series File!')\n",
        "  TS_List = read_Dir_TS\n",
        "else:\n",
        "  print('INFO: Start Analyzing '+ Data_NAME + ' Time Series List!')\n",
        "  TS_List = Read_Timeseries['Series_num']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5LewQI1kZ0i",
        "outputId": "3c996139-d556-4da1-cbff-e79afcfdb02a"
      },
      "id": "w5LewQI1kZ0i",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: Start Analyzing Krebs_Cycle Time Series List!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tested"
      ],
      "metadata": {
        "id": "_SE8d5bu14h1"
      },
      "id": "_SE8d5bu14h1"
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "\n",
        "File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "os.chdir(File_PATH)\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\")\n",
        "\n",
        "# self.File_PATH\n",
        "read_Dir=os.listdir(File_PATH)\n",
        "Data_NAME = 'real_dataset_processed'\n",
        "print(File_PATH)\n",
        "\n",
        "def readable_File(path):\n",
        "    read_Dir=os.listdir(path)\n",
        "    count = 0\n",
        "    readable_File = []\n",
        "    for f in read_Dir:\n",
        "      file = os.path.join(path, f)\n",
        "      if os.path.isdir(file):\n",
        "        count = count+1\n",
        "      else:\n",
        "        readable_File.append(f)\n",
        "    return count,readable_File\n",
        "\n",
        "readable_File(File_PATH)[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHnZl8_mDWh",
        "outputId": "c3f73152-6ac1-413b-9f01-fd4b1abb12a2"
      },
      "id": "hwHnZl8_mDWh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['series_list.csv',\n",
              " 'real_dataset_processed.csv',\n",
              " 'true_graph.csv',\n",
              " 'stock-market.txt',\n",
              " 'linearGauss_6_15.npz',\n",
              " '18V_55N_Wireless.tar.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File_NAME = data\\\\\n",
        "Readable_File = readable_File(File_PATH)[1]\n",
        "num_readable_File = len(read_Dir) - readable_File(File_PATH)[0]\n",
        "TS_path = File_PATH+Data_NAME+'_TS/'\n",
        "if len(read_Dir) == 0:\n",
        "    print('INFO: No Data Under the Current Route!')\n",
        "else:\n",
        "    File_NAME = []\n",
        "    File_TYPE = []\n",
        "    for i in Readable_File:\n",
        "      File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "      File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "    # Deal with Two Dimensions Causality Data\n",
        "    if Data_NAME+'.npz' in Readable_File:\n",
        "      Tests_data = np.load(Data_NAME+'.npz', allow_pickle=True)\n",
        "      Raw_data = Tests_data['x']\n",
        "      # print(Raw_data)\n",
        "      true_dag = Tests_data['y']\n",
        "      # print(true_dag)\n",
        "\n",
        "    elif Data_NAME+'.tar.gz' in Readable_File:\n",
        "      # open file\n",
        "      file = tarfile.open(File_PATH+Data_NAME+'.tar.gz')\n",
        "\n",
        "      # print file names\n",
        "      file_names = file.getnames()\n",
        "      # extract files\n",
        "      file.extractall(File_PATH)\n",
        "\n",
        "      # close file\n",
        "      file.close()\n",
        "\n",
        "      # x = np.load(File_PATH+file_names[1])\n",
        "      Raw_data = pd.read_csv(File_PATH+file_names[1])\n",
        "      # print(Raw_data)\n",
        "      true_dag = np.load(File_PATH+file_names[2])\n",
        "      # print(true_dag)\n",
        "      '''\n",
        "      # 将两个 numpy 数组保存到 npz 文件中\n",
        "      np.savez(Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "\n",
        "      # 从 npz 文件中加载数据\n",
        "      data = np.load(Data_NAME+'.npz')\n",
        "      Raw_data = Tests_data['x']\n",
        "      true_dag = Tests_data['y']\n",
        "      '''\n",
        "\n",
        "    elif Data_NAME+'.csv' in Readable_File:\n",
        "      Raw_data = pd.read_csv(File_PATH+ Data_NAME+'.csv', header=0, index_col=0)\n",
        "      print(Raw_data)\n",
        "      true_dag = pd.read_csv(File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "      print(true_dag)\n",
        "############################################################\n",
        "    # Deal with Multi-dimensions Data\n",
        "    elif os.path.exists(TS_path):\n",
        "      read_Dir_TS=os.listdir(TS_path)\n",
        "      Timeseries_List_path = File_PATH+'series_list.csv'\n",
        "      Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "      # print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "      if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "        print('INFO: Start Analyzing '+ Data_NAME + ' Time Series File!')\n",
        "        TS_List = read_Dir_TS\n",
        "      else:\n",
        "        print('INFO: Start Analyzing '+ Data_NAME + ' Time Series List!')\n",
        "        TS_List = Read_Timeseries['Series_num']\n",
        "\n",
        "      # for i, j in combinations(range(len(TS_List)), 2):\n",
        "      [i, j] = [1,2]\n",
        "      x = pd.read_csv(TS_path+TS_List[i], header=0, index_col=0)\n",
        "      y = pd.read_csv(TS_path+TS_List[j], header=0, index_col=0)\n",
        "      print(TS_List[i], TS_List[j])\n",
        "    else:\n",
        "      print('INFO: Wrong DataType!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pMuVUUbhOqA",
        "outputId": "c4270c54-2ab4-41c1-9c72-7b9b2a87f202"
      },
      "id": "-pMuVUUbhOqA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  A_10  ...  A_47  A_48  A_49  \\\n",
            "A_0                                                     ...                     \n",
            "0      1    0    0    0    0    0    4    0    1     0  ...     0     0     0   \n",
            "0      0    0    0    0    0    0    4    0    0     0  ...     3     0     0   \n",
            "0      0    0    0    0    0    3    2    0    1     0  ...     3     2     0   \n",
            "0      2    0    0    0    0    0    4    0    3     0  ...     0     2     0   \n",
            "0      4    0    0    0    0    0   11    0    4     0  ...     0     2     0   \n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   ...   \n",
            "0      0    0    0    0    0    0    0    0    0     0  ...     3     0     0   \n",
            "0      1    0    0    0    0    0    5    0    4     0  ...     0     3     0   \n",
            "0      3    0    0    0    0    0    4    0    1     0  ...     0     2     0   \n",
            "0      1    0    0    0    0    0    1    0    1     0  ...     0     1     0   \n",
            "0      0    0    0    0    0    0    3    0    1     0  ...     0     1     0   \n",
            "\n",
            "     A_50  A_51  A_52  A_53  A_54  A_55  A_56  \n",
            "A_0                                            \n",
            "0       0     1     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       1     2     0     0     0     0     0  \n",
            "0       0     6     0     0     0     0     0  \n",
            "0       0    14     0     0     0     0     0  \n",
            "..    ...   ...   ...   ...   ...   ...   ...  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "\n",
            "[22589 rows x 54 columns]\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  ...  A_47  A_48  A_49  \\\n",
            "A_0     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_1     0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_2     0    0    0    0    1    1    0    0    1    1  ...     1     1     1   \n",
            "A_3     0    0    0    0    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_4     0    0    0    1    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_5     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_6     0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_7     0    1    0    1    0    0    0    0    0    1  ...     0     1     0   \n",
            "A_8     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_9     0    0    0    1    0    0    1    0    1    0  ...     0     0     1   \n",
            "A_10    0    0    0    1    0    0    1    0    1    1  ...     1     1     0   \n",
            "A_11    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_12    0    0    0    0    0    0    1    0    0    0  ...     0     0     0   \n",
            "A_13    0    0    0    1    1    0    1    0    1    0  ...     0     1     1   \n",
            "A_14    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_15    0    0    0    1    1    0    1    0    0    0  ...     1     0     1   \n",
            "A_16    0    0    0    1    1    0    1    0    0    0  ...     1     0     0   \n",
            "A_17    0    0    0    1    0    0    1    0    1    0  ...     0     0     1   \n",
            "A_18    0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_19    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
            "A_20    0    1    0    1    0    0    1    0    1    1  ...     1     0     1   \n",
            "A_22    0    0    0    0    0    1    0    0    0    0  ...     0     1     0   \n",
            "A_23    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_24    0    0    0    1    0    0    1    0    1    0  ...     1     0     1   \n",
            "A_25    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_26    0    0    0    1    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_27    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_28    0    0    0    0    1    0    0    0    0    1  ...     0     0     0   \n",
            "A_29    0    0    0    1    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_30    0    0    0    1    0    0    1    0    1    1  ...     0     1     1   \n",
            "A_31    0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_32    0    0    0    1    0    0    1    1    1    1  ...     0     1     0   \n",
            "A_33    0    1    0    1    1    1    1    1    1    1  ...     1     1     1   \n",
            "A_35    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_36    0    0    0    1    0    0    1    1    1    1  ...     1     1     0   \n",
            "A_37    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_38    0    0    0    1    0    0    1    0    1    1  ...     1     0     0   \n",
            "A_39    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_40    0    0    0    1    0    0    1    0    1    0  ...     1     0     0   \n",
            "A_41    0    0    0    1    0    1    1    1    1    1  ...     1     1     1   \n",
            "A_42    0    0    0    1    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_43    0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_44    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_45    0    0    0    0    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_46    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_47    0    0    0    1    0    0    1    0    1    1  ...     1     0     1   \n",
            "A_48    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_49    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_50    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_51    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_52    0    1    0    1    1    0    1    0    0    1  ...     1     0     1   \n",
            "A_53    0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_54    0    0    0    1    1    0    1    0    1    0  ...     1     0     1   \n",
            "A_55    0    0    0    0    0    1    0    0    0    0  ...     0     0     0   \n",
            "A_56    1    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "\n",
            "      A_50  A_51  A_52  A_53  A_54  A_55  A_56  \n",
            "A_0      0     0     0     0     0     0     0  \n",
            "A_1      1     1     0     0     0     0     0  \n",
            "A_2      1     1     1     0     1     1     0  \n",
            "A_3      0     0     0     0     0     0     0  \n",
            "A_4      0     0     0     0     0     0     0  \n",
            "A_5      0     0     0     0     0     0     0  \n",
            "A_6      0     0     0     0     0     0     0  \n",
            "A_7      0     0     0     0     0     1     0  \n",
            "A_8      0     0     0     0     0     0     0  \n",
            "A_9      1     1     0     0     0     1     0  \n",
            "A_10     0     0     0     0     0     1     0  \n",
            "A_11     0     0     0     0     0     0     0  \n",
            "A_12     0     0     0     0     0     0     0  \n",
            "A_13     1     1     0     0     0     0     0  \n",
            "A_14     0     0     0     0     0     0     0  \n",
            "A_15     0     1     0     0     0     0     0  \n",
            "A_16     0     0     0     0     0     0     0  \n",
            "A_17     0     0     0     0     0     1     0  \n",
            "A_18     0     0     0     0     0     0     0  \n",
            "A_19     1     1     0     0     0     0     0  \n",
            "A_20     1     1     0     0     0     0     0  \n",
            "A_22     0     0     0     0     0     0     0  \n",
            "A_23     0     0     0     0     0     0     0  \n",
            "A_24     1     1     0     0     0     1     0  \n",
            "A_25     0     0     0     0     0     0     0  \n",
            "A_26     1     1     0     0     0     1     0  \n",
            "A_27     0     0     0     0     0     0     0  \n",
            "A_28     0     0     0     0     0     1     0  \n",
            "A_29     0     0     0     0     0     0     0  \n",
            "A_30     0     1     0     0     0     1     0  \n",
            "A_31     0     0     0     0     0     0     0  \n",
            "A_32     1     1     0     0     0     1     0  \n",
            "A_33     1     1     1     0     1     1     0  \n",
            "A_35     0     0     0     0     0     0     0  \n",
            "A_36     1     1     0     0     0     1     0  \n",
            "A_37     0     0     0     0     0     0     0  \n",
            "A_38     1     1     0     0     0     1     0  \n",
            "A_39     0     0     0     0     0     0     0  \n",
            "A_40     1     1     0     0     0     0     0  \n",
            "A_41     1     1     0     0     0     1     0  \n",
            "A_42     1     1     0     0     0     0     0  \n",
            "A_43     0     0     0     0     0     0     0  \n",
            "A_44     0     0     0     0     0     0     0  \n",
            "A_45     1     1     0     0     0     1     0  \n",
            "A_46     0     0     0     0     0     0     0  \n",
            "A_47     1     1     0     0     0     1     0  \n",
            "A_48     0     0     0     0     0     0     0  \n",
            "A_49     0     0     0     0     0     0     0  \n",
            "A_50     1     0     0     0     0     0     0  \n",
            "A_51     0     0     0     0     0     0     0  \n",
            "A_52     1     1     0     0     0     0     0  \n",
            "A_53     0     0     0     0     0     0     0  \n",
            "A_54     0     1     0     0     0     0     0  \n",
            "A_55     0     0     0     0     0     0     0  \n",
            "A_56     0     0     0     0     0     0     0  \n",
            "\n",
            "[55 rows x 55 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}