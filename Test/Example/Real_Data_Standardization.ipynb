{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "kq1OSo5X0whe",
      "metadata": {
        "id": "kq1OSo5X0whe"
      },
      "source": [
        "#ANMNCPOP_Real_Data_Standardization\n",
        "Welcome to the example for real data standardization in causal discovery!\n",
        "\n",
        "# Input Data Form:\n",
        "-------------------------------------------------------\n",
        "The data can be any format that is supported by the Real_Data_Standardization() function, currently including tar.gz, csv and tsv.\n",
        "\n",
        "**Two Dimensions Causality Data:**\n",
        "* **tar.gz file**\n",
        "\n",
        "Archiving and compressing causality files and folders as a tar.gz file.\n",
        "\n",
        "* **csv files**\n",
        "\n",
        "Raw data and casaul matrix are saved in separate csv files.\n",
        "\n",
        "**Multiple Features Time Series:**\n",
        "* **tsv files**\n",
        "\n",
        "Single sample trajectory with multiple features Time Series as shape of (F features, T timeSets) - incluing S smples, i.e. S number of .tsv files\n",
        "\n",
        "# Standardization process:\n",
        "-------------------------------------------------------\n",
        "* Causality Data stored as NumPy array x and y under a npz file.\n",
        "* For multiple features time series data, all time series are reorganized as a (Feature_num, Sample_num, Time_sets) three-dims array for applying ANM-NCPOP.\n",
        "\n",
        "# Output Data Form\n",
        "-------------------------------------------------------\n",
        "For further analysis, all useful infomation is extracted and saved as **npz file** storing causality Data as NumPy array x and y.\n",
        "\n",
        "* **x**\n",
        "\n",
        "An array saves F features and S smples.\n",
        "\n",
        "Or an array saves F features, S smples and T timesets Time Series.\n",
        "\n",
        "* **y**\n",
        "\n",
        "A causal matrix is saved as shape of (F features, F features)\n",
        "\n",
        "Learned underlying causal relationships between obeservations, according to expert experience or ground true causality.\n",
        "\n",
        "# Examples\n",
        "-------------------------------------------------------\n",
        "In our paper, we tested Telephone, Microwave and Krebs_Cycle data in respect to testing orignal two dimensions data and multi-features time series.\n",
        "\n",
        "* Telephone\n",
        "\n",
        "Rawdata is saved as real_dataset_processed.csv, and\n",
        "the causal_matrix is saved as true_graph.csv.\n",
        "\n",
        "* Microwave\n",
        "\n",
        "Rawdata is saved in Alarm.csv and causal_matrix is saved in DAG.npy.\n",
        "\n",
        "Examples: 25V_474N_Microwave.tar.gz, 24V_439N_Microwave.tar.gz, 18V_55N_Wireless.tar.gz.\n",
        "\n",
        "* Krebs_Cycle\n",
        "\n",
        "Multiple features time series are saved under file Krebs_Cycle_TS. The causal_matrix is saved as true_graph.csv.\n",
        "\n",
        "Krebs_Cycle Output:\n",
        "* __x__: is an array in shape(F, S, T), where the number of row F is features_num, the number of column S is smples_num and the number of deep T is timesets.\n",
        "* __y__: is a nonsymmetric square matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Po_zr02dCTVJ",
      "metadata": {
        "id": "Po_zr02dCTVJ"
      },
      "source": [
        "#__Get start__\n",
        "\n",
        "\n",
        "* mount drive\n",
        "* set envirment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PquTJd-1eTSe",
      "metadata": {
        "id": "PquTJd-1eTSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20deb445-6762-48e8-db40-ed1b89a0ddd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP/Causal_Models_Learning/Test/\")\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "DINBSSHDde5W",
      "metadata": {
        "id": "DINBSSHDde5W"
      },
      "outputs": [],
      "source": [
        "# from Data_Standardization import*\n",
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "import urllib\n",
        "import hashlib\n",
        "from urllib.error import URLError\n",
        "USER_AGENT = \"gcastle/dataset\"\n",
        "\n",
        "def _check_exist(root, filename, files):\n",
        "    path_exist = os.path.join(root, filename.split('.')[0])\n",
        "    processed_folder_exists = os.path.exists(path_exist)\n",
        "    if not processed_folder_exists:\n",
        "        return False\n",
        "\n",
        "    return all(\n",
        "        _check_integrity(os.path.join(path_exist, file)) for file in files\n",
        "    )\n",
        "\n",
        "def _read_data(root, filename, files):\n",
        "    path_exist = os.path.join(root, filename.split('.')[0])\n",
        "\n",
        "    result = []\n",
        "    for file in files:\n",
        "        if file.split('.')[-1] == 'csv':\n",
        "            file_path = os.path.join(path_exist, file)\n",
        "            result.append(pd.read_csv(file_path))\n",
        "        elif file.split('.')[-1] == 'npy':\n",
        "            file_path = os.path.join(path_exist, file)\n",
        "            result.append(np.load(file_path))\n",
        "\n",
        "    if len(result) == 2:\n",
        "        result.append(None)\n",
        "\n",
        "    return result\n",
        "\n",
        "def _check_integrity(fpath, md5=None):\n",
        "    if not os.path.isfile(fpath):\n",
        "        return False\n",
        "    if md5 is None:\n",
        "        return True\n",
        "\n",
        "    md5f = hashlib.md5()\n",
        "    with open(fpath, 'rb') as f:\n",
        "        md5f.update(f.read())\n",
        "\n",
        "    return md5 == md5f.hexdigest()\n",
        "\n",
        "\n",
        "def _download(root, url, filename, md5):\n",
        "    \"\"\"Download the datasets if it doesn't exist already.\"\"\"\n",
        "\n",
        "    os.makedirs(root, exist_ok=True)\n",
        "\n",
        "    # download files\n",
        "    for mirror in url:\n",
        "        filepath = \"{}{}\".format(mirror, filename)\n",
        "        savegz = os.path.join(root, filename)\n",
        "        try:\n",
        "            print(\"Downloading {}\".format(filepath))\n",
        "            response = urllib.request.urlopen( \\\n",
        "                urllib.request.Request( \\\n",
        "                    filepath, headers={\"User-Agent\": USER_AGENT}))\n",
        "            with open(savegz, \"wb\") as fh:\n",
        "                fh.write(response.read())\n",
        "\n",
        "            tar = tarfile.open(savegz)\n",
        "            names = tar.getnames()\n",
        "            for name in names:\n",
        "                tar.extract(name, path=root)\n",
        "            tar.close()\n",
        "        except URLError as error:\n",
        "            print(\"Failed to download (trying next):\\n{}\".format(error))\n",
        "            continue\n",
        "        break\n",
        "    else:\n",
        "        raise RuntimeError(\"Error downloading {}\".format(filename))\n",
        "\n",
        "    # check integrity of downloaded file\n",
        "    if not _check_integrity(savegz, md5):\n",
        "        raise RuntimeError(\"File not found or corrupted.\")\n",
        "\n",
        "def load_dataset(name='IID_Test', root=None, download=False):\n",
        "    \"\"\"\n",
        "    A function for loading some well-known datasets.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name: class, default='IID_Test'\n",
        "        Dataset name, independent and identically distributed (IID),\n",
        "        Topological Hawkes Process (THP) and real datasets.\n",
        "    root: str\n",
        "        Root directory in which the dataset will be saved.\n",
        "    download: bool\n",
        "        If true, downloads the dataset from the internet and\n",
        "        puts it in root directory. If dataset is already downloaded, it is not\n",
        "        downloaded again.\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    out: tuple\n",
        "        true_graph_matrix: numpy.matrix\n",
        "            adjacency matrix for the target causal graph.\n",
        "        topology_matrix: numpy.matrix\n",
        "            adjacency matrix for the topology.\n",
        "        data: pandas.core.frame.DataFrame\n",
        "            standard trainning dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    if name not in DataSetRegistry.meta.keys():\n",
        "        raise ValueError('The dataset {} has not been registered, you can use'\n",
        "                         ' ''castle.datasets.__builtin_dataset__'' to get registered '\n",
        "                         'dataset list'.format(name))\n",
        "    loader = DataSetRegistry.meta.get(name)()\n",
        "    loader.load(root, download)\n",
        "    return loader.data, loader.true_graph_matrix, loader.topology_matrix\n",
        "\n",
        "\n",
        "class BuiltinDataSet(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self._data = None\n",
        "        self._true_graph_matrix = None\n",
        "        self._topology_matrix = None\n",
        "\n",
        "    def load(self, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        return self._data\n",
        "\n",
        "    @property\n",
        "    def true_graph_matrix(self):\n",
        "        return self._true_graph_matrix\n",
        "\n",
        "    @property\n",
        "    def topology_matrix(self):\n",
        "        return self._topology_matrix\n",
        "\n",
        "class RealDataSet(BuiltinDataSet):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.url = None\n",
        "        self.tar_file = None\n",
        "        self.md5 = None\n",
        "        self.file_list = None\n",
        "\n",
        "    def load(self, root=None, download=False):\n",
        "\n",
        "        if root is None:\n",
        "            root = './'\n",
        "\n",
        "        if _check_exist(root, self.tar_file, self.file_list):\n",
        "            self._data, self._true_graph_matrix, self._topology_matrix = \\\n",
        "                _read_data(root, self.tar_file, self.file_list)\n",
        "            return\n",
        "\n",
        "        if download:\n",
        "            _download(root, self.url, self.tar_file, self.md5)\n",
        "\n",
        "        if not _check_exist(root, self.tar_file, self.file_list):\n",
        "            raise RuntimeError('Dataset not found.' +\n",
        "                               ' You can use download=True to download it.')\n",
        "\n",
        "        self._data, self._true_graph_matrix, self._topology_matrix = \\\n",
        "            _read_data(root, self.tar_file, self.file_list)\n",
        "\n",
        "\n",
        "class V18_N55_Wireless(RealDataSet):\n",
        "    \"\"\"\n",
        "    A function for loading the real dataset: V18_N55_Wireless\n",
        "    url: https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/18V_55N_Wireless.tar.gz\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.url = ['https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/']\n",
        "        self.tar_file = \"18V_55N_Wireless.tar.gz\"\n",
        "        self.md5 = \"36ee135b86c8dbe09668d9284c23575b\"\n",
        "        self.file_list = ['Alarm.csv', 'DAG.npy']\n",
        "\n",
        "\n",
        "class V24_N439_Microwave(RealDataSet):\n",
        "    \"\"\"\n",
        "    A function for loading the real dataset: V24_N439_Microwave\n",
        "    url: https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/24V_439N_Microwave.tar.gz\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.url = ['https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/']\n",
        "        self.tar_file = \"24V_439N_Microwave.tar.gz\"\n",
        "        self.md5 = \"b4c8b32d34c04a86aa93c7259f7d086c\"\n",
        "        self.file_list = ['Alarm.csv', 'DAG.npy', 'Topology.npy']\n",
        "\n",
        "\n",
        "class V25_N474_Microwave(RealDataSet):\n",
        "    \"\"\"\n",
        "    A function for loading the real dataset: V25_N474_Microwave\n",
        "    url: https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/25V_474N_Microwave.tar.gz\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.url = ['https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/']\n",
        "        self.tar_file = \"25V_474N_Microwave.tar.gz\"\n",
        "        self.md5 = \"51f43ed622d4b44ef6daf8fabf81e162\"\n",
        "        self.file_list = ['Alarm.csv', 'DAG.npy', 'Topology.npy']\n",
        "\n",
        "\n",
        "class DataSetRegistry(object):\n",
        "    '''\n",
        "    A class for resgistering the datasets, in which each dataset\n",
        "    can be loaded by 'load_dataset' api.\n",
        "    '''\n",
        "\n",
        "    meta = {'V18_N55_Wireless': V18_N55_Wireless,\n",
        "            'V24_N439_Microwave': V24_N439_Microwave,\n",
        "            'V25_N474_Microwave': V25_N474_Microwave}\n",
        "\n",
        "\n",
        "\n",
        "class Real_Data_Standardization(object):\n",
        "    '''\n",
        "    A class for preparing data to simulate random (causal) DAG.\n",
        "\n",
        "    Parameters\n",
        "    ------------------------------------------------------------------------------------------------\n",
        "    File_PATH: str\n",
        "               Read file path\n",
        "    File_NAME: str\n",
        "               Read data name\n",
        "\n",
        "    Returns\n",
        "    ------------------------------------------------------------------------------------------------\n",
        "    Input data: npz\n",
        "            Raw_data：[d, n, T] sample time series\n",
        "            true_dag: true_causal_matrix\n",
        "    File_PATH_Datasets:\n",
        "            Route of saving test data\n",
        "\n",
        "    Examples\n",
        "    -------------------------------------------------------------------------------------------------\n",
        "    >>> File_PATH = \"../Test/Examples/Test_data/\"\n",
        "    >>> file_name = 'Telephone'\n",
        "    >>> dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "    >>> dt.standardize_data()\n",
        "\n",
        "    >>> File_PATH = \"../Test/Datasets/Synthetic datasets/Krebs_Cycle/\"\n",
        "    >>> file_name = 'Krebs_Cycle'\n",
        "    >>> dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "    >>> dt.standardize_data()\n",
        "\n",
        "    >>> File_PATH = \"../Test/Datasets/Real_data/Microwave/\"\n",
        "    >>> file_name = 'V24_N439_Microwave'\n",
        "    >>> dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "    >>> dt.standardize_data()\n",
        "    '''\n",
        "\n",
        "    def __init__(self, File_PATH='Kreb_Cycles/', filename='Krebs_Cycle'):\n",
        "        self.File_PATH = File_PATH\n",
        "        self.filename = filename\n",
        "\n",
        "    def standardize_data(self):\n",
        "        ################################################  Create Ground Tier Folders #############################################\n",
        "        self.File_PATH_Base = self.File_PATH +'Result_'+ self.filename +'/'\n",
        "\n",
        "        ################################################  Create First Tier Folders #############################################\n",
        "        self.File_PATH_Datasets = self.File_PATH_Base + 'Datasets_'+ self.filename +'/'\n",
        "        if not os.path.exists(self.File_PATH_Datasets):\n",
        "            os.makedirs(self.File_PATH_Datasets)\n",
        "        print('ANM-NCPOP INFO: Created Datasets' + ' File!')\n",
        "\n",
        "        Raw_data = Real_Data_Standardization.Produce_Rawdata(self)[0]\n",
        "        true_dag = Real_Data_Standardization.Produce_Rawdata(self)[1]\n",
        "\n",
        "        # save numpy to npz file\n",
        "        nn = len(true_dag)\n",
        "        ne = np.count_nonzero(true_dag)\n",
        "        data_name = self.filename  +'_'+str(nn)+'Nodes_'+str(ne)+'Edges_TS'\n",
        "        if self.filename in ['IID_Test','THP_Test','V18_N55_Wireless', 'V24_N439_Microwave', 'V25_N474_Microwave']:\n",
        "            topology_matrix_devices = Real_Data_Standardization.Produce_Rawdata(self)[2]\n",
        "            np.savez(self.File_PATH_Datasets + data_name +'.npz', x=Raw_data , y=true_dag , z=topology_matrix_devices)\n",
        "        else:\n",
        "            np.savez(self.File_PATH_Datasets + data_name +'.npz', x=Raw_data , y=true_dag)\n",
        "        print('ANM-NCPOP INFO: Finished '+ data_name+' dataset standardization!')\n",
        "\n",
        "    @staticmethod\n",
        "    def Produce_Rawdata(self):\n",
        "\n",
        "        def readable_File(FilePATH):\n",
        "            read_Dir=os.listdir(FilePATH)\n",
        "            count = 0\n",
        "            readable_F = []\n",
        "            for f in read_Dir:\n",
        "                file = os.path.join(FilePATH, f)\n",
        "                if os.path.isdir(file):\n",
        "                    count = count+1\n",
        "                else:\n",
        "                    readable_F.append(f)\n",
        "            return count,readable_F\n",
        "\n",
        "        self.Read_File = readable_File(self.File_PATH)[1]\n",
        "\n",
        "        # Website data\n",
        "        if self.filename in ['IID_Test','THP_Test','V18_N55_Wireless', 'V24_N439_Microwave', 'V25_N474_Microwave']:\n",
        "            Raw_data, true_dag, topology_matrix_devices  = load_dataset(self.filename, download=True)\n",
        "            return Raw_data, true_dag, topology_matrix_devices\n",
        "\n",
        "        else:\n",
        "            # Check empty files under riute\n",
        "            if len(self.Read_File ) == 0:\n",
        "                raise ValueError('No Data Under the Current Route!')\n",
        "            else:\n",
        "                self.File_PATH_TS = self.File_PATH +self.filename +'_TS/'\n",
        "                File_NAME = []\n",
        "                File_TYPE = []\n",
        "                # Delete files and list readable Files\n",
        "                for i in self.Read_File:\n",
        "                    File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "                    File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "                ###################################### Deal with Two Dimensions Causality Data ###################################\n",
        "                if self.filename+'.npz' in self.Read_File:\n",
        "                    Test_data = np.load(self.File_PATH + self.filename+'.npz', allow_pickle=True)\n",
        "                    Raw_data = Test_data['x']\n",
        "                    true_dag = Test_data['y']\n",
        "                    return Raw_data, true_dag\n",
        "\n",
        "                elif self.filename+'.tar.gz' in self.Read_File:\n",
        "                    # open file\n",
        "                    file = tarfile.open(self.File_PATH + self.filename + '.tar.gz')\n",
        "                    file_names = file.getnames()\n",
        "                    # extract files\n",
        "                    file.extractall(self.File_PATH)\n",
        "                    file.close()\n",
        "                    Raw_data = np.load(self.File_PATH+file_names[2])\n",
        "                    true_dag = pd.read_csv(self.File_PATH+file_names[3])\n",
        "                    return Raw_data, true_dag\n",
        "\n",
        "                elif self.filename+'.csv' in self.Read_File:\n",
        "                    Raw_data = pd.read_csv(self.File_PATH+ self.filename+'.csv', header=0, index_col=False)\n",
        "                    true_dag = pd.read_csv(self.File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "                    return Raw_data, true_dag\n",
        "\n",
        "                ################################ Deal with Multi-dimensions Causality Data ###################################\n",
        "                elif os.path.exists(self.File_PATH_TS):\n",
        "                    read_Dir_TS=os.listdir(self.File_PATH_TS)\n",
        "                    true_graph = np.load(self.File_PATH+'true_graph.npz')\n",
        "\n",
        "                    # labels = [\"FUMARATE\", \"GTP\", \"H2O\", \"CIS-ACONITATE\", \"MALATE\",\n",
        "                    # \"OXALOACETATE\", \"FAD\", \"SUCCINYL-COA\", \"NAD\",\n",
        "                    #           \"A-K-GLUTARATE\", \"GDP\", \"NADH\", \"CITRATE\", \"SUCCINATE\",\n",
        "                    # \"ISOCITRATE\", \"ACETY-COA\"]\n",
        "                    #true_dag = pd.DataFrame(true_graph['arr_0'],  index=labels, columns=labels)\n",
        "                    true_dag = pd.DataFrame(true_graph['arr_0'])\n",
        "\n",
        "                    # print(true_dag)\n",
        "                    lds = pd.read_csv(self.File_PATH_TS+ read_Dir_TS[0], delimiter='\\t', index_col=0, header=None)\n",
        "                    feature_name = np.array(lds.index)\n",
        "                    feature_num = len(feature_name)\n",
        "                    sample_num = len(read_Dir_TS)\n",
        "                    T_num = lds.shape[1]\n",
        "                    # if labels == feature_name:\n",
        "                    Raw_data = np.zeros((feature_num, sample_num, T_num))\n",
        "                    for ns in range(sample_num):\n",
        "                        X = pd.read_csv(self.File_PATH_TS+ read_Dir_TS[ns], delimiter='\\t', index_col=0, header=None)\n",
        "                        X_trans = np.transpose(X)\n",
        "                        for fn in range(feature_num):\n",
        "                            Raw_data[fn, ns, :] = list(X_trans[feature_name[fn]])\n",
        "                    return Raw_data, true_dag\n",
        "\n",
        "                else:\n",
        "                    raise ValueError('Unknown input data type.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NijYqL8iaRSZ",
      "metadata": {
        "id": "NijYqL8iaRSZ"
      },
      "outputs": [],
      "source": [
        "__builtin_dataset__ = DataSetRegistry.meta.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X8go85wbaRZJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8go85wbaRZJ",
        "outputId": "dc6bca9a-612d-4790-ddf3-cb5c6d15dd45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['V18_N55_Wireless', 'V24_N439_Microwave', 'V25_N474_Microwave'])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "__builtin_dataset__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xSjM6iP9d3yM",
      "metadata": {
        "id": "xSjM6iP9d3yM"
      },
      "outputs": [],
      "source": [
        "X, true_dag, topology_matrix = load_dataset(name='IID_Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4kDPtbteNwQ",
      "metadata": {
        "id": "b4kDPtbteNwQ"
      },
      "outputs": [],
      "source": [
        "X, true_causal_matrix, topology_matrix = load_dataset('THP_Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59xnCtjYeN0D",
      "metadata": {
        "id": "59xnCtjYeN0D"
      },
      "outputs": [],
      "source": [
        "X, true_causal_matrix, topology_matrix  = load_dataset('V24_N439_Microwave', download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DDJ3kkiPeN3-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDJ3kkiPeN3-",
        "outputId": "a7a4a78e-ff49-4e70-dce5-04b071edba4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "alarm_id               23\n",
              "device_id             438\n",
              "start_timestamp    518368\n",
              "end_timestamp      518368\n",
              "dtype: int64"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hBwJZ3XpLjwV",
      "metadata": {
        "id": "hBwJZ3XpLjwV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gOVDdxekg9O4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gOVDdxekg9O4",
        "outputId": "94970ca2-e9f3-456a-d89c-6a5349029990"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "X['device_id'].plot(kind='hist', bins=20, title='alarm_id')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tM_54dg1fqQl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM_54dg1fqQl",
        "outputId": "6ec90726-5eb4-4c7a-c6fd-e49e88624720"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 24)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "true_causal_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMNT8ZaGfqUp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMNT8ZaGfqUp",
        "outputId": "00c9aa24-43e1-44c6-a547-29acbd04da62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(439, 439)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topology_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bLtPEw3od7Oh",
      "metadata": {
        "id": "bLtPEw3od7Oh"
      },
      "source": [
        "## __Test 1: Telephone_55Nodes_587Edges__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bzjIMcHdd3R",
      "metadata": {
        "id": "1bzjIMcHdd3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b479339-ae9f-4037-d59f-23513530d484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANM-NCPOP INFO: Created Datasets File!\n",
            "ANM-NCPOP INFO: Finished Telephone_55Nodes_587Edges_TS dataset standardization!\n"
          ]
        }
      ],
      "source": [
        "File_PATH = \"../Test/Examples/Test_data/\"\n",
        "file_name = 'Telephone'\n",
        "dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "dt.standardize_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "joc33E4AeBX6",
      "metadata": {
        "id": "joc33E4AeBX6"
      },
      "source": [
        "## __Test 2: Krebs_Cycle_16Nodes_43Edge__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5gqa2ZtTeIlL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gqa2ZtTeIlL",
        "outputId": "bb8de28b-edae-44d3-a2d8-abb23e9fec69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANM-NCPOP INFO: Created Datasets File!\n",
            "ANM-NCPOP INFO: Finished Krebs_Cycle_16Nodes_43Edges_TS dataset standardization!\n"
          ]
        }
      ],
      "source": [
        "# Krebs_Cycle\n",
        "File_PATH = \"../Test/Datasets/Synthetic datasets/Krebs_Cycle/\"\n",
        "file_name = 'Krebs_Cycle'\n",
        "dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "dt.standardize_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rD3kwtoVeAW1",
      "metadata": {
        "id": "rD3kwtoVeAW1"
      },
      "source": [
        "## __Test 3: Microwave_25Alarm_474Devices__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_A_twkRMeFvN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A_twkRMeFvN",
        "outputId": "f7ac6b9c-9f38-496b-d8c7-e5997cfd1101"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANM-NCPOP INFO: Created Datasets File!\n",
            "ANM-NCPOP INFO: Finished V24_N439_Microwave_24Nodes_137Edges_TS dataset standardization!\n"
          ]
        }
      ],
      "source": [
        "File_PATH = \"../Test/Datasets/Real_data/Microwave/\"\n",
        "file_name = 'V24_N439_Microwave'\n",
        "dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "dt.standardize_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mbQ5MNiNdr6y",
      "metadata": {
        "id": "mbQ5MNiNdr6y"
      },
      "source": [
        "# __Step-by-Step__"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vK-ciKBQTALM",
      "metadata": {
        "id": "vK-ciKBQTALM"
      },
      "source": [
        "##__Step 1: Standardized Data class__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URW4L5m4qjw-",
      "metadata": {
        "id": "URW4L5m4qjw-"
      },
      "outputs": [],
      "source": [
        "# from Data_Standardization import*\n",
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "\n",
        "class Real_Data_Standardization(object):\n",
        "    '''\n",
        "    A class for preparing data to simulate random (causal) DAG.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    File_PATH: str\n",
        "        Read file path\n",
        "    File_NAME: str\n",
        "        Read data name\n",
        "    '''\n",
        "\n",
        "    def __init__(self, File_PATH, Data_NAME):\n",
        "        self.File_PATH = File_PATH\n",
        "        self.Data_NAME = Data_NAME\n",
        "\n",
        "    def Produce_Rawdata(self):\n",
        "\n",
        "        def readable_File(FilePATH):\n",
        "            read_Dir=os.listdir(FilePATH)\n",
        "            count = 0\n",
        "            readable_F = []\n",
        "            for f in read_Dir:\n",
        "                file = os.path.join(FilePATH, f)\n",
        "                if os.path.isdir(file):\n",
        "                    count = count+1\n",
        "                else:\n",
        "                    readable_F.append(f)\n",
        "            return count,readable_F\n",
        "\n",
        "        self.Read_File = readable_File(self.File_PATH)[1]\n",
        "        self.TS_path = self.File_PATH + self.Data_NAME + '_TS/'\n",
        "\n",
        "        # Check empty files under riute\n",
        "        if len(self.File_PATH) == 0:\n",
        "            print('INFO: No Data Under the Current Route!')\n",
        "        else:\n",
        "            File_NAME = []\n",
        "            File_TYPE = []\n",
        "\n",
        "            # Delete files and list readable Files\n",
        "            for i in self.Read_File:\n",
        "                File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "                File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "            ###################################### Deal with Two Dimensions Causality Data ###################################\n",
        "            '''if self.Data_NAME+'.npz' in self.Read_File:\n",
        "                Tests_data = np.load(self.File_PATH + self.Data_NAME+'.npz', allow_pickle=True)\n",
        "                Raw_data = Tests_data['x']\n",
        "                true_dag = Tests_data['y']\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')'''\n",
        "\n",
        "            if self.Data_NAME+'.tar.gz' in self.Read_File:\n",
        "                # open file\n",
        "                file = tarfile.open(self.File_PATH + self.Data_NAME + '.tar.gz')\n",
        "\n",
        "                # print file names\n",
        "                file_names = file.getnames()\n",
        "                print(file_names)\n",
        "\n",
        "                # extract files\n",
        "                file.extractall(self.File_PATH)\n",
        "\n",
        "                # close file\n",
        "                file.close()\n",
        "\n",
        "                Raw_data = np.load(self.File_PATH+file_names[2])\n",
        "                true_dag = pd.read_csv(self.File_PATH+file_names[3])\n",
        "\n",
        "                # save numpy to npz file\n",
        "                np.savez(self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            elif self.Data_NAME+'.csv' in self.Read_File:\n",
        "                Raw_data = pd.read_csv(self.File_PATH+ self.Data_NAME+'.csv', header=0, index_col=False)\n",
        "                true_dag = pd.read_csv(self.File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "\n",
        "                # save numpy to npz file\n",
        "                np.savez(self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            ################################ Deal with Multi-dimensions Causality Data ###################################\n",
        "            elif os.path.exists(self.TS_path):\n",
        "                read_Dir_TS=os.listdir(self.TS_path)\n",
        "                true_graph = np.load(self.File_PATH+'true_graph.npz')\n",
        "\n",
        "                labels = [\"FUMARATE\", \"GTP\", \"H2O\", \"CIS-ACONITATE\", \"MALATE\",\n",
        "                \"OXALOACETATE\", \"FAD\", \"SUCCINYL-COA\", \"NAD\",\n",
        "                          \"A-K-GLUTARATE\", \"GDP\", \"NADH\", \"CITRATE\", \"SUCCINATE\",\n",
        "                \"ISOCITRATE\", \"ACETY-COA\"]\n",
        "                true_dag = pd.DataFrame(true_graph['arr_0'],  index=labels, columns=labels)\n",
        "                # print(true_dag)\n",
        "                lds = pd.read_csv(self.TS_path+ read_Dir_TS[0], delimiter='\\t', index_col=0, header=None)\n",
        "                feature_name = np.array(lds.index)\n",
        "                # lds_trans = np.transpose(lds)\n",
        "                # feature_name = lds_trans.columns\n",
        "                feature_num = len(feature_name)\n",
        "                sample_num = len(read_Dir_TS)\n",
        "                T_num = lds.shape[1]\n",
        "                # if labels == feature_name:\n",
        "                df = np.zeros((feature_num, sample_num, T_num))\n",
        "                Raw_data = np.zeros((feature_num, sample_num *T_num))\n",
        "                for ns in range(sample_num):\n",
        "                    X = pd.read_csv(self.TS_path+ read_Dir_TS[ns], delimiter='\\t', index_col=0, header=None)\n",
        "                    X_trans = np.transpose(X)\n",
        "                    for fn in range(feature_num):\n",
        "                        df[fn, ns, :] = list(X_trans[feature_name[fn]])\n",
        "                for fn in range(feature_num):\n",
        "                    Raw_data[fn, :] = list(df[fn, :, :].reshape(-1))\n",
        "\n",
        "                non_zero_count = np.count_nonzero(true_dag)\n",
        "\n",
        "                # save numpy to npz file\n",
        "                sname = self.Data_NAME + '_'+str(feature_num)+'_'+str(non_zero_count)+'_TS_1'\n",
        "                np.savez(sname+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+sname + '!')\n",
        "\n",
        "            else:\n",
        "                print('INFO: Wrong DataType!')\n",
        "\n",
        "            '''\n",
        "            ################################ Deal with Multi-dimensions Causality Data ###################################\n",
        "            elif os.path.exists(self.TS_path):\n",
        "                read_Dir_TS=os.listdir(self.TS_path)\n",
        "                # true_dag = pd.read_csv(self.File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "                true_graph = np.load(self.File_PATH+'true_graph.npz')\n",
        "\n",
        "                labels = [\"FUMARATE\", \"GTP\", \"H2O\", \"CIS-ACONITATE\", \"MALATE\",\n",
        "                \"OXALOACETATE\", \"FAD\", \"SUCCINYL-COA\", \"NAD\",\n",
        "                          \"A-K-GLUTARATE\", \"GDP\", \"NADH\", \"CITRATE\", \"SUCCINATE\",\n",
        "                \"ISOCITRATE\", \"ACETY-COA\"]\n",
        "                true_dag = pd.DataFrame(true_graph['arr_0'],  index=labels, columns=labels)\n",
        "                # print(true_dag)\n",
        "                lds = pd.read_csv(self.TS_path+ read_Dir_TS[0], delimiter='\\t', index_col=0, header=None)\n",
        "                feature_name = np.array(lds.index)\n",
        "                # lds_trans = np.transpose(lds)\n",
        "                # feature_name = lds_trans.columns\n",
        "                feature_num = len(feature_name)\n",
        "                sample_num = len(read_Dir_TS)\n",
        "                T_num = lds.shape[1]\n",
        "                # if labels == feature_name:\n",
        "                Raw_data = np.zeros((feature_num, sample_num, T_num))\n",
        "                for ns in range(sample_num):\n",
        "                    X = pd.read_csv(self.TS_path+ read_Dir_TS[ns], delimiter='\\t', index_col=0, header=None)\n",
        "                    X_trans = np.transpose(X)\n",
        "                    for fn in range(feature_num):\n",
        "                        Raw_data[fn, ns, :] = list(X_trans[feature_name[fn]])\n",
        "                non_zero_count = np.count_nonzero(true_dag)\n",
        "\n",
        "                # save numpy to npz file\n",
        "                sname = self.Data_NAME + '_'+str(feature_num)+'_'+str(non_zero_count)+'_TS'\n",
        "                np.savez(sname+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+sname + '!')'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "u_4vgMBI1eFQ",
      "metadata": {
        "id": "u_4vgMBI1eFQ"
      },
      "source": [
        "##__Step 2: Test__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ai2O_kDa23fJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2O_kDa23fJ",
        "outputId": "1abe9bd9-f727-4602-f355-eb4b644eb289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: Check for Krebs_Cycle_16_43_TS_1!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ############################################################################################################\n",
        "    ############################################ SETTING File_PATH and file_name ###############################\n",
        "    ############################################################################################################\n",
        "    # Krebs_Cycle\n",
        "    File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP/Causal_Models_Learning/Test/Datasets/Synthetic datasets/Krebs_Cycle/\"\n",
        "    file_name = 'Krebs_Cycle'\n",
        "\n",
        "    '''\n",
        "    # Microwave\n",
        "    File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP/Causal_Models_Learning/Test/Datasets/Real_data/Microwave/\"\n",
        "    file_name = '25V_474N_Microwave'\n",
        "\n",
        "    # Telephone\n",
        "    File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP/Causal_Models_Learning/Test/Datasets/Real_data/Telephone/\"\n",
        "    file_name = 'Telephone'\n",
        "\n",
        "    '''\n",
        "\n",
        "    dt = Real_Data_Standardization(File_PATH, file_name)\n",
        "    dt.Produce_Rawdata()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffyb1rzWydCR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffyb1rzWydCR",
        "outputId": "15b05d14-8751-42db-d238-94d13f31cdf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 60000) (16, 16)\n"
          ]
        }
      ],
      "source": [
        "data = np.load('Krebs_Cycle_16_43_TS_1.npz')\n",
        "Raw_data = data['x']\n",
        "true_dag = data['y']\n",
        "print(Raw_data.shape, true_dag.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i9WfAVotsbxZ",
      "metadata": {
        "id": "i9WfAVotsbxZ"
      },
      "source": [
        "# Backup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZCPDiPrGpDQ0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCPDiPrGpDQ0",
        "outputId": "dd610c41-4e9e-4fd3-bd2f-d578024fec40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 6)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = np.zeros((4, 2*3))\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NCjEDGWcpdRK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCjEDGWcpdRK",
        "outputId": "7d99246e-50b7-4da2-fa15-c2e9d6d369aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 2, 3)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = np.zeros((4, 2,3))\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E7Y5FRv8QyUD",
      "metadata": {
        "id": "E7Y5FRv8QyUD"
      },
      "outputs": [],
      "source": [
        "# from Data_Standardization import*\n",
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "\n",
        "class Real_Data_Standardization(object):\n",
        "    '''\n",
        "    A class for preparing data to simulate random (causal) DAG.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    File_PATH: str\n",
        "        Save file path\n",
        "    File_NAME: str\n",
        "        Read data name\n",
        "    '''\n",
        "\n",
        "    def __init__(self, File_PATH, Data_NAME):\n",
        "        self.File_PATH = File_PATH\n",
        "        self.Data_NAME = Data_NAME\n",
        "\n",
        "    def Produce_Rawdata(self):\n",
        "\n",
        "        def readable_File(FilePATH):\n",
        "            read_Dir=os.listdir(FilePATH)\n",
        "            count = 0\n",
        "            readable_F = []\n",
        "            for f in read_Dir:\n",
        "                file = os.path.join(FilePATH, f)\n",
        "                if os.path.isdir(file):\n",
        "                    count = count+1\n",
        "                else:\n",
        "                    readable_F.append(f)\n",
        "            return count,readable_F\n",
        "\n",
        "        self.Read_File = readable_File(self.File_PATH)[1]\n",
        "        self.TS_path = self.File_PATH + self.Data_NAME + '_TS/'\n",
        "\n",
        "        # Check empty files under riute\n",
        "        if len(self.File_PATH) == 0:\n",
        "            print('INFO: No Data Under the Current Route!')\n",
        "        else:\n",
        "            File_NAME = []\n",
        "            File_TYPE = []\n",
        "\n",
        "            # Delete files and list readable Files\n",
        "            for i in self.Read_File:\n",
        "                File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "                File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "            ###################################### Deal with Two Dimensions Causality Data ###################################\n",
        "            if self.Data_NAME+'.npz' in self.Read_File:\n",
        "                Tests_data = np.load(self.File_PATH + self.Data_NAME+'.npz', allow_pickle=True)\n",
        "                Raw_data = Tests_data['x']\n",
        "                true_dag = Tests_data['y']\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            elif self.Data_NAME+'.tar.gz' in self.Read_File:\n",
        "                # open file\n",
        "                file = tarfile.open(self.File_PATH + self.Data_NAME + '.tar.gz')\n",
        "\n",
        "                # print file names\n",
        "                file_names = file.getnames()\n",
        "                print(file_names)\n",
        "\n",
        "                # extract files\n",
        "                file.extractall(self.File_PATH)\n",
        "\n",
        "                # close file\n",
        "                file.close()\n",
        "\n",
        "                Raw_data = pd.read_csv(self.File_PATH+file_names[1])\n",
        "                true_dag = np.load(self.File_PATH+file_names[2])\n",
        "\n",
        "                # save numpy to npz file\n",
        "                np.savez(self.File_PATH + self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            elif self.Data_NAME+'.csv' in self.Read_File:\n",
        "                Raw_data = pd.read_csv(self.File_PATH+ self.Data_NAME+'.csv', header=0, index_col=0)\n",
        "                true_dag = pd.read_csv(self.File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "\n",
        "                # save numpy to npz file\n",
        "                np.savez(self.File_PATH + self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            ################################ Deal with Multi-dimensions Causality Data ###################################\n",
        "            elif os.path.exists(self.TS_path):\n",
        "                read_Dir_TS=os.listdir(self.TS_path)\n",
        "                Timeseries_List_path = self.File_PATH+'series_list.csv'\n",
        "                Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "                # print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "                if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "                    print('INFO: Start Analyzing '+ self.Data_NAME + ' Time Series File!')\n",
        "                    TS_List = read_Dir_TS\n",
        "                else:\n",
        "                    print('INFO: Start Analyzing '+ self.Data_NAME + ' Time Series List!')\n",
        "                    TS_List = Read_Timeseries['Series_num']\n",
        "                lds = pd.read_csv(self.TS_path+ TS_List[0], delimiter='\\t', index_col=0, header=None)\n",
        "                # print(lds)\n",
        "                n = len(TS_List)\n",
        "                T = lds.shape[1]\n",
        "                # d = lds.shape[0]\n",
        "                # print(d, T, n)\n",
        "                df = np.transpose(lds)\n",
        "                feature_name = df.columns\n",
        "                d = len(feature_name)\n",
        "                Raw_data = np.zeros((d, n, T))\n",
        "                for ns in range(n):\n",
        "                    X = pd.read_csv(self.TS_path+ TS_List[ns], delimiter='\\t', index_col=0, header=None)\n",
        "                    df = np.transpose(X)\n",
        "                    feature_name = df.columns\n",
        "                    for fn in range(d):\n",
        "                        Raw_data[fn, ns, :] = list(df[feature_name[fn]])\n",
        "                # print(Raw_data.shape)\n",
        "                # save numpy to npz file\n",
        "                matrix = np.zeros((d, d))\n",
        "                np.fill_diagonal(matrix, 0)\n",
        "                np.fill_diagonal(matrix[:, 1:], 1)\n",
        "                np.savez(self.File_PATH + self.Data_NAME+'.npz', x=Raw_data , y=matrix)\n",
        "                print('INFO: Check for '+self.Data_NAME +'.npz'+ '!')\n",
        "\n",
        "            else:\n",
        "                print('INFO: Wrong DataType!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p-cnYLZkBZn4",
      "metadata": {
        "id": "p-cnYLZkBZn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "File_PATH = '/content/drive/MyDrive/Colab Notebooks/Causality_NotesTest/Test_Causality_Datasets/Telephone/'\n",
        "Raw_data_path = File_PATH+'real_dataset_processed.csv'\n",
        "Raw_dag_path = File_PATH+'true_graph.csv'\n",
        "\n",
        "x = pd.read_csv(Raw_data_path, header=0)\n",
        "y = pd.read_csv(Raw_dag_path, header=0, index_col=0)\n",
        "\n",
        "np.savez('/content/drive/MyDrive/Colab Notebooks/Causality_NotesTest/Test_Causality_Datasets/Real_data/Telephone.npz', x=x, y=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5AZGUtcqX1aF",
      "metadata": {
        "id": "5AZGUtcqX1aF"
      },
      "source": [
        "##Debug class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w5LewQI1kZ0i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5LewQI1kZ0i",
        "outputId": "3c996139-d556-4da1-cbff-e79afcfdb02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: Start Analyzing Krebs_Cycle Time Series List!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "from itertools import combinations\n",
        "from pickle import TRUE\n",
        "\n",
        "File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "os.chdir(File_PATH)\n",
        "read_Dir=os.listdir(File_PATH)\n",
        "Data_NAME = 'Krebs_Cycle'\n",
        "Readable_File = readable_File(File_PATH)[1]\n",
        "num_readable_File = len(read_Dir) - readable_File(File_PATH)[0]\n",
        "TS_path = File_PATH+Data_NAME+'_TS/'\n",
        "\n",
        "def readable_File(path):\n",
        "    read_Dir=os.listdir(path)\n",
        "    count = 0\n",
        "    readable_File = []\n",
        "    for f in read_Dir:\n",
        "      file = os.path.join(path, f)\n",
        "      if os.path.isdir(file):\n",
        "        count = count+1\n",
        "      else:\n",
        "        readable_File.append(f)\n",
        "    return count,readable_File\n",
        "\n",
        "read_Dir_TS=os.listdir(TS_path)\n",
        "Timeseries_List_path = File_PATH+'series_list.csv'\n",
        "Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "# print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "  print('INFO: Start Analyzing '+ Data_NAME + ' Time Series File!')\n",
        "  TS_List = read_Dir_TS\n",
        "else:\n",
        "  print('INFO: Start Analyzing '+ Data_NAME + ' Time Series List!')\n",
        "  TS_List = Read_Timeseries['Series_num']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_SE8d5bu14h1",
      "metadata": {
        "id": "_SE8d5bu14h1"
      },
      "source": [
        "##Tested"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hwHnZl8_mDWh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHnZl8_mDWh",
        "outputId": "c3f73152-6ac1-413b-9f01-fd4b1abb12a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['series_list.csv',\n",
              " 'real_dataset_processed.csv',\n",
              " 'true_graph.csv',\n",
              " 'stock-market.txt',\n",
              " 'linearGauss_6_15.npz',\n",
              " '18V_55N_Wireless.tar.gz']"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "\n",
        "File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "os.chdir(File_PATH)\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\")\n",
        "\n",
        "# self.File_PATH\n",
        "read_Dir=os.listdir(File_PATH)\n",
        "Data_NAME = 'real_dataset_processed'\n",
        "print(File_PATH)\n",
        "\n",
        "def readable_File(path):\n",
        "    read_Dir=os.listdir(path)\n",
        "    count = 0\n",
        "    readable_File = []\n",
        "    for f in read_Dir:\n",
        "      file = os.path.join(path, f)\n",
        "      if os.path.isdir(file):\n",
        "        count = count+1\n",
        "      else:\n",
        "        readable_File.append(f)\n",
        "    return count,readable_File\n",
        "\n",
        "readable_File(File_PATH)[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-pMuVUUbhOqA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pMuVUUbhOqA",
        "outputId": "c4270c54-2ab4-41c1-9c72-7b9b2a87f202"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  A_10  ...  A_47  A_48  A_49  \\\n",
            "A_0                                                     ...                     \n",
            "0      1    0    0    0    0    0    4    0    1     0  ...     0     0     0   \n",
            "0      0    0    0    0    0    0    4    0    0     0  ...     3     0     0   \n",
            "0      0    0    0    0    0    3    2    0    1     0  ...     3     2     0   \n",
            "0      2    0    0    0    0    0    4    0    3     0  ...     0     2     0   \n",
            "0      4    0    0    0    0    0   11    0    4     0  ...     0     2     0   \n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   ...   \n",
            "0      0    0    0    0    0    0    0    0    0     0  ...     3     0     0   \n",
            "0      1    0    0    0    0    0    5    0    4     0  ...     0     3     0   \n",
            "0      3    0    0    0    0    0    4    0    1     0  ...     0     2     0   \n",
            "0      1    0    0    0    0    0    1    0    1     0  ...     0     1     0   \n",
            "0      0    0    0    0    0    0    3    0    1     0  ...     0     1     0   \n",
            "\n",
            "     A_50  A_51  A_52  A_53  A_54  A_55  A_56  \n",
            "A_0                                            \n",
            "0       0     1     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       1     2     0     0     0     0     0  \n",
            "0       0     6     0     0     0     0     0  \n",
            "0       0    14     0     0     0     0     0  \n",
            "..    ...   ...   ...   ...   ...   ...   ...  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "\n",
            "[22589 rows x 54 columns]\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  ...  A_47  A_48  A_49  \\\n",
            "A_0     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_1     0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_2     0    0    0    0    1    1    0    0    1    1  ...     1     1     1   \n",
            "A_3     0    0    0    0    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_4     0    0    0    1    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_5     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_6     0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_7     0    1    0    1    0    0    0    0    0    1  ...     0     1     0   \n",
            "A_8     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_9     0    0    0    1    0    0    1    0    1    0  ...     0     0     1   \n",
            "A_10    0    0    0    1    0    0    1    0    1    1  ...     1     1     0   \n",
            "A_11    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_12    0    0    0    0    0    0    1    0    0    0  ...     0     0     0   \n",
            "A_13    0    0    0    1    1    0    1    0    1    0  ...     0     1     1   \n",
            "A_14    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_15    0    0    0    1    1    0    1    0    0    0  ...     1     0     1   \n",
            "A_16    0    0    0    1    1    0    1    0    0    0  ...     1     0     0   \n",
            "A_17    0    0    0    1    0    0    1    0    1    0  ...     0     0     1   \n",
            "A_18    0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_19    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
            "A_20    0    1    0    1    0    0    1    0    1    1  ...     1     0     1   \n",
            "A_22    0    0    0    0    0    1    0    0    0    0  ...     0     1     0   \n",
            "A_23    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_24    0    0    0    1    0    0    1    0    1    0  ...     1     0     1   \n",
            "A_25    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_26    0    0    0    1    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_27    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_28    0    0    0    0    1    0    0    0    0    1  ...     0     0     0   \n",
            "A_29    0    0    0    1    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_30    0    0    0    1    0    0    1    0    1    1  ...     0     1     1   \n",
            "A_31    0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_32    0    0    0    1    0    0    1    1    1    1  ...     0     1     0   \n",
            "A_33    0    1    0    1    1    1    1    1    1    1  ...     1     1     1   \n",
            "A_35    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_36    0    0    0    1    0    0    1    1    1    1  ...     1     1     0   \n",
            "A_37    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_38    0    0    0    1    0    0    1    0    1    1  ...     1     0     0   \n",
            "A_39    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_40    0    0    0    1    0    0    1    0    1    0  ...     1     0     0   \n",
            "A_41    0    0    0    1    0    1    1    1    1    1  ...     1     1     1   \n",
            "A_42    0    0    0    1    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_43    0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_44    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_45    0    0    0    0    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_46    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_47    0    0    0    1    0    0    1    0    1    1  ...     1     0     1   \n",
            "A_48    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_49    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_50    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_51    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_52    0    1    0    1    1    0    1    0    0    1  ...     1     0     1   \n",
            "A_53    0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_54    0    0    0    1    1    0    1    0    1    0  ...     1     0     1   \n",
            "A_55    0    0    0    0    0    1    0    0    0    0  ...     0     0     0   \n",
            "A_56    1    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "\n",
            "      A_50  A_51  A_52  A_53  A_54  A_55  A_56  \n",
            "A_0      0     0     0     0     0     0     0  \n",
            "A_1      1     1     0     0     0     0     0  \n",
            "A_2      1     1     1     0     1     1     0  \n",
            "A_3      0     0     0     0     0     0     0  \n",
            "A_4      0     0     0     0     0     0     0  \n",
            "A_5      0     0     0     0     0     0     0  \n",
            "A_6      0     0     0     0     0     0     0  \n",
            "A_7      0     0     0     0     0     1     0  \n",
            "A_8      0     0     0     0     0     0     0  \n",
            "A_9      1     1     0     0     0     1     0  \n",
            "A_10     0     0     0     0     0     1     0  \n",
            "A_11     0     0     0     0     0     0     0  \n",
            "A_12     0     0     0     0     0     0     0  \n",
            "A_13     1     1     0     0     0     0     0  \n",
            "A_14     0     0     0     0     0     0     0  \n",
            "A_15     0     1     0     0     0     0     0  \n",
            "A_16     0     0     0     0     0     0     0  \n",
            "A_17     0     0     0     0     0     1     0  \n",
            "A_18     0     0     0     0     0     0     0  \n",
            "A_19     1     1     0     0     0     0     0  \n",
            "A_20     1     1     0     0     0     0     0  \n",
            "A_22     0     0     0     0     0     0     0  \n",
            "A_23     0     0     0     0     0     0     0  \n",
            "A_24     1     1     0     0     0     1     0  \n",
            "A_25     0     0     0     0     0     0     0  \n",
            "A_26     1     1     0     0     0     1     0  \n",
            "A_27     0     0     0     0     0     0     0  \n",
            "A_28     0     0     0     0     0     1     0  \n",
            "A_29     0     0     0     0     0     0     0  \n",
            "A_30     0     1     0     0     0     1     0  \n",
            "A_31     0     0     0     0     0     0     0  \n",
            "A_32     1     1     0     0     0     1     0  \n",
            "A_33     1     1     1     0     1     1     0  \n",
            "A_35     0     0     0     0     0     0     0  \n",
            "A_36     1     1     0     0     0     1     0  \n",
            "A_37     0     0     0     0     0     0     0  \n",
            "A_38     1     1     0     0     0     1     0  \n",
            "A_39     0     0     0     0     0     0     0  \n",
            "A_40     1     1     0     0     0     0     0  \n",
            "A_41     1     1     0     0     0     1     0  \n",
            "A_42     1     1     0     0     0     0     0  \n",
            "A_43     0     0     0     0     0     0     0  \n",
            "A_44     0     0     0     0     0     0     0  \n",
            "A_45     1     1     0     0     0     1     0  \n",
            "A_46     0     0     0     0     0     0     0  \n",
            "A_47     1     1     0     0     0     1     0  \n",
            "A_48     0     0     0     0     0     0     0  \n",
            "A_49     0     0     0     0     0     0     0  \n",
            "A_50     1     0     0     0     0     0     0  \n",
            "A_51     0     0     0     0     0     0     0  \n",
            "A_52     1     1     0     0     0     0     0  \n",
            "A_53     0     0     0     0     0     0     0  \n",
            "A_54     0     1     0     0     0     0     0  \n",
            "A_55     0     0     0     0     0     0     0  \n",
            "A_56     0     0     0     0     0     0     0  \n",
            "\n",
            "[55 rows x 55 columns]\n"
          ]
        }
      ],
      "source": [
        "# File_NAME = data\\\\\n",
        "Readable_File = readable_File(File_PATH)[1]\n",
        "num_readable_File = len(read_Dir) - readable_File(File_PATH)[0]\n",
        "TS_path = File_PATH+Data_NAME+'_TS/'\n",
        "if len(read_Dir) == 0:\n",
        "    print('INFO: No Data Under the Current Route!')\n",
        "else:\n",
        "    File_NAME = []\n",
        "    File_TYPE = []\n",
        "    for i in Readable_File:\n",
        "      File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "      File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "    # Deal with Two Dimensions Causality Data\n",
        "    if Data_NAME+'.npz' in Readable_File:\n",
        "      Tests_data = np.load(Data_NAME+'.npz', allow_pickle=True)\n",
        "      Raw_data = Tests_data['x']\n",
        "      # print(Raw_data)\n",
        "      true_dag = Tests_data['y']\n",
        "      # print(true_dag)\n",
        "\n",
        "    elif Data_NAME+'.tar.gz' in Readable_File:\n",
        "      # open file\n",
        "      file = tarfile.open(File_PATH+Data_NAME+'.tar.gz')\n",
        "\n",
        "      # print file names\n",
        "      file_names = file.getnames()\n",
        "      # extract files\n",
        "      file.extractall(File_PATH)\n",
        "\n",
        "      # close file\n",
        "      file.close()\n",
        "\n",
        "      # x = np.load(File_PATH+file_names[1])\n",
        "      Raw_data = pd.read_csv(File_PATH+file_names[1])\n",
        "      # print(Raw_data)\n",
        "      true_dag = np.load(File_PATH+file_names[2])\n",
        "      # print(true_dag)\n",
        "      '''\n",
        "      # 将两个 numpy 数组保存到 npz 文件中\n",
        "      np.savez(Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "\n",
        "      # 从 npz 文件中加载数据\n",
        "      data = np.load(Data_NAME+'.npz')\n",
        "      Raw_data = Tests_data['x']\n",
        "      true_dag = Tests_data['y']\n",
        "      '''\n",
        "\n",
        "    elif Data_NAME+'.csv' in Readable_File:\n",
        "      Raw_data = pd.read_csv(File_PATH+ Data_NAME+'.csv', header=0, index_col=0)\n",
        "      print(Raw_data)\n",
        "      true_dag = pd.read_csv(File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "      print(true_dag)\n",
        "############################################################\n",
        "    # Deal with Multi-dimensions Data\n",
        "    elif os.path.exists(TS_path):\n",
        "      read_Dir_TS=os.listdir(TS_path)\n",
        "      Timeseries_List_path = File_PATH+'series_list.csv'\n",
        "      Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "      # print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "      if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "        print('INFO: Start Analyzing '+ Data_NAME + ' Time Series File!')\n",
        "        TS_List = read_Dir_TS\n",
        "      else:\n",
        "        print('INFO: Start Analyzing '+ Data_NAME + ' Time Series List!')\n",
        "        TS_List = Read_Timeseries['Series_num']\n",
        "\n",
        "      # for i, j in combinations(range(len(TS_List)), 2):\n",
        "      [i, j] = [1,2]\n",
        "      x = pd.read_csv(TS_path+TS_List[i], header=0, index_col=0)\n",
        "      y = pd.read_csv(TS_path+TS_List[j], header=0, index_col=0)\n",
        "      print(TS_List[i], TS_List[j])\n",
        "    else:\n",
        "      print('INFO: Wrong DataType!')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
