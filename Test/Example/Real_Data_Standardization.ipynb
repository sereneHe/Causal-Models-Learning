{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data-Standardization\n",
        "* The data can be in any format supported by the ANMPOP_ReadData() function, including npy, tar.gz, csv and tsv.\n",
        "\n",
        "# Standardized Data Form:\n",
        "Causality Data stored as NumPy array x and y under a npz file.\n",
        "\n",
        "**Raw_data:**\n",
        "\n",
        "Causality data with F features, S smples and T timesets.\n",
        "\n",
        "**True_dag:**\n",
        "\n",
        "Causal_matrix array as shape of (F features, F features)"
      ],
      "metadata": {
        "id": "kq1OSo5X0whe"
      },
      "id": "kq1OSo5X0whe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_zr02dCTVJ"
      },
      "source": [
        "#__Step 1: Get start__\n",
        "\n",
        "\n",
        "* mount drive\n",
        "* set envirment\n",
        "* install packages"
      ],
      "id": "Po_zr02dCTVJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHf74wQIVx2v",
        "outputId": "5c4a72bc-10c6-4db3-fed4-a9157114da8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\")\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/Details_Krebs_Cycle/MetricsDAG/\")\n"
      ],
      "id": "oHf74wQIVx2v"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 2: Standardized Data class__"
      ],
      "metadata": {
        "id": "vK-ciKBQTALM"
      },
      "id": "vK-ciKBQTALM"
    },
    {
      "cell_type": "code",
      "source": [
        "class ANMPOP_ReadData(object):\n",
        "    '''\n",
        "    A class for preparing data to simulate random (causal) DAG.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    File_PATH: str\n",
        "        Save file path\n",
        "    File_NAME: str\n",
        "        Read data name\n",
        "    '''\n",
        "\n",
        "    def __init__(self, File_PATH, Data_NAME):\n",
        "        self.File_PATH = File_PATH\n",
        "        self.Data_NAME = Data_NAME\n",
        "\n",
        "\n",
        "    def readable_File(self):\n",
        "        read_Dir=os.listdir(self.File_PATH)\n",
        "        count = 0\n",
        "        readable_File = []\n",
        "        for f in read_Dir:\n",
        "            file = os.path.join(self.File_PATH, f)\n",
        "            if os.path.isdir(file):\n",
        "                count = count+1\n",
        "            else:\n",
        "                readable_File.append(f)\n",
        "        return count,readable_File\n",
        "\n",
        "    @staticmethod\n",
        "    def Produce_Rawdata(self):\n",
        "        Readable_File = self.readable_File(self.File_PATH)[1]\n",
        "        # num_readable_File = len(self.File_PATH) - self.readable_File(self.File_PATH)[0]\n",
        "        self.TS_path = self.File_PATH + self.Data_NAME + '_TS/'\n",
        "\n",
        "        # Check empty files under riute\n",
        "        if len(self.File_PATH) == 0:\n",
        "            print('INFO: No Data Under the Current Route!')\n",
        "        else:\n",
        "            File_NAME = []\n",
        "            File_TYPE = []\n",
        "\n",
        "            # Delete files and list readable Files\n",
        "            for i in Readable_File:\n",
        "                File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "                File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "            ###################################### Deal with Two Dimensions Causality Data ###################################\n",
        "            if self.Data_NAME+'.npz' in Readable_File:\n",
        "                Tests_data = np.load(self.Data_NAME+'.npz', allow_pickle=True)\n",
        "                Raw_data = Tests_data['x']\n",
        "                true_dag = Tests_data['y']\n",
        "\n",
        "            elif self.Data_NAME+'.tar.gz' in Readable_File:\n",
        "                # open file\n",
        "                file = tarfile.open(self.File_PATH + self.Data_NAME + '.tar.gz')\n",
        "\n",
        "                # print file names\n",
        "                file_names = file.getnames()\n",
        "                print(file_names)\n",
        "\n",
        "                # extract files\n",
        "                file.extractall(self.File_PATH)\n",
        "\n",
        "                # close file\n",
        "                file.close()\n",
        "\n",
        "                Raw_data = pd.read_csv(self.File_PATH+file_names[1])\n",
        "                true_dag = np.load(self.File_PATH+file_names[2])\n",
        "\n",
        "            elif self.Data_NAME+'.csv' in Readable_File:\n",
        "                Raw_data = pd.read_csv(self.File_PATH+ self.Data_NAME+'.csv', header=0, index_col=0)\n",
        "                true_dag = pd.read_csv(self.File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "\n",
        "                # 将两个 numpy 数组保存到 npz 文件中\n",
        "                np.savez(self.Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "\n",
        "            ################################ Deal with Multi-dimensions Causality Data ###################################\n",
        "            elif os.path.exists(self.TS_path):\n",
        "                read_Dir_TS=os.listdir(self.TS_path)\n",
        "                Timeseries_List_path = self.File_PATH+'series_list.csv'\n",
        "                Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "                # print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "                if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "                    print('INFO: Start Analyzing '+ self.Data_NAME + ' Time Series File!')\n",
        "                    TS_List = read_Dir_TS\n",
        "                else:\n",
        "                    print('INFO: Start Analyzing '+ self.Data_NAME + ' Time Series List!')\n",
        "                    TS_List = Read_Timeseries['Series_num']\n",
        "                    '''\n",
        "                    # for i, j in combinations(range(len(TS_List)), 2):\n",
        "                    [i, j] = [1,2]\n",
        "                    x = pd.read_csv(TS_path+TS_List[i], header=0, index_col=0)\n",
        "                    y = pd.read_csv(TS_path+TS_List[j], header=0, index_col=0)\n",
        "                    print(TS_List[i], TS_List[j])\n",
        "                    '''\n",
        "            else:\n",
        "                print('INFO: Wrong DataType!')\n"
      ],
      "metadata": {
        "id": "E7Y5FRv8QyUD"
      },
      "id": "E7Y5FRv8QyUD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 3: Test__"
      ],
      "metadata": {
        "id": "u_4vgMBI1eFQ"
      },
      "id": "u_4vgMBI1eFQ"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    ############################################################################################################\n",
        "    ############################################ SETTING File_PATH and file_name ###############################\n",
        "    ############################################################################################################\n",
        "\n",
        "    File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "    file_name = 'linearGauss_6_15'\n",
        "    dt = ANMPOP_ReadData(File_PATH, file_name)\n",
        "    dt.Produce_Rawdata()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "ai2O_kDa23fJ",
        "outputId": "c156b38e-03d2-4288-b4f7-cab7075cf535"
      },
      "id": "ai2O_kDa23fJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ANMPOP_ReadData.Produce_Rawdata() missing 1 required positional argument: 'self'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2fb461538787>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linearGauss_6_15'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANMPOP_ReadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFile_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProduce_Rawdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: ANMPOP_ReadData.Produce_Rawdata() missing 1 required positional argument: 'self'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 4: Debug class__"
      ],
      "metadata": {
        "id": "5AZGUtcqX1aF"
      },
      "id": "5AZGUtcqX1aF"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "from itertools import combinations\n",
        "from pickle import TRUE\n",
        "\n",
        "File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "os.chdir(File_PATH)\n",
        "read_Dir=os.listdir(File_PATH)\n",
        "Data_NAME = 'Krebs_Cycle'\n",
        "Readable_File = readable_File(File_PATH)[1]\n",
        "num_readable_File = len(read_Dir) - readable_File(File_PATH)[0]\n",
        "TS_path = File_PATH+Data_NAME+'_TS/'\n",
        "\n",
        "def readable_File(path):\n",
        "    read_Dir=os.listdir(path)\n",
        "    count = 0\n",
        "    readable_File = []\n",
        "    for f in read_Dir:\n",
        "      file = os.path.join(path, f)\n",
        "      if os.path.isdir(file):\n",
        "        count = count+1\n",
        "      else:\n",
        "        readable_File.append(f)\n",
        "    return count,readable_File\n",
        "\n",
        "read_Dir_TS=os.listdir(TS_path)\n",
        "Timeseries_List_path = File_PATH+'series_list.csv'\n",
        "Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "# print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "  print('INFO: Start Analyzing '+ Data_NAME + ' Time Series File!')\n",
        "  TS_List = read_Dir_TS\n",
        "else:\n",
        "  print('INFO: Start Analyzing '+ Data_NAME + ' Time Series List!')\n",
        "  TS_List = Read_Timeseries['Series_num']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5LewQI1kZ0i",
        "outputId": "3c996139-d556-4da1-cbff-e79afcfdb02a"
      },
      "id": "w5LewQI1kZ0i",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO: Start Analyzing Krebs_Cycle Time Series List!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 5: Tested__"
      ],
      "metadata": {
        "id": "_SE8d5bu14h1"
      },
      "id": "_SE8d5bu14h1"
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "from itertools import combinations\n",
        "\n",
        "File_PATH = \"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\"\n",
        "os.chdir(File_PATH)\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\")\n",
        "\n",
        "# self.File_PATH\n",
        "read_Dir=os.listdir(File_PATH)\n",
        "Data_NAME = 'real_dataset_processed'\n",
        "print(File_PATH)\n",
        "\n",
        "def readable_File(path):\n",
        "    read_Dir=os.listdir(path)\n",
        "    count = 0\n",
        "    readable_File = []\n",
        "    for f in read_Dir:\n",
        "      file = os.path.join(path, f)\n",
        "      if os.path.isdir(file):\n",
        "        count = count+1\n",
        "      else:\n",
        "        readable_File.append(f)\n",
        "    return count,readable_File\n",
        "\n",
        "readable_File(File_PATH)[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwHnZl8_mDWh",
        "outputId": "c3f73152-6ac1-413b-9f01-fd4b1abb12a2"
      },
      "id": "hwHnZl8_mDWh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['series_list.csv',\n",
              " 'real_dataset_processed.csv',\n",
              " 'true_graph.csv',\n",
              " 'stock-market.txt',\n",
              " 'linearGauss_6_15.npz',\n",
              " '18V_55N_Wireless.tar.gz']"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# File_NAME = data\\\\\n",
        "Readable_File = readable_File(File_PATH)[1]\n",
        "num_readable_File = len(read_Dir) - readable_File(File_PATH)[0]\n",
        "TS_path = File_PATH+Data_NAME+'_TS/'\n",
        "if len(read_Dir) == 0:\n",
        "    print('INFO: No Data Under the Current Route!')\n",
        "else:\n",
        "    File_NAME = []\n",
        "    File_TYPE = []\n",
        "    for i in Readable_File:\n",
        "      File_NAME.append(re.split(\"\\.\", i)[0])\n",
        "      File_TYPE.append(re.split(\"\\.\", i)[1])\n",
        "\n",
        "    # Deal with Two Dimensions Causality Data\n",
        "    if Data_NAME+'.npz' in Readable_File:\n",
        "      Tests_data = np.load(Data_NAME+'.npz', allow_pickle=True)\n",
        "      Raw_data = Tests_data['x']\n",
        "      # print(Raw_data)\n",
        "      true_dag = Tests_data['y']\n",
        "      # print(true_dag)\n",
        "\n",
        "    elif Data_NAME+'.tar.gz' in Readable_File:\n",
        "      # open file\n",
        "      file = tarfile.open(File_PATH+Data_NAME+'.tar.gz')\n",
        "\n",
        "      # print file names\n",
        "      file_names = file.getnames()\n",
        "      # extract files\n",
        "      file.extractall(File_PATH)\n",
        "\n",
        "      # close file\n",
        "      file.close()\n",
        "\n",
        "      # x = np.load(File_PATH+file_names[1])\n",
        "      Raw_data = pd.read_csv(File_PATH+file_names[1])\n",
        "      # print(Raw_data)\n",
        "      true_dag = np.load(File_PATH+file_names[2])\n",
        "      # print(true_dag)\n",
        "      '''\n",
        "      # 将两个 numpy 数组保存到 npz 文件中\n",
        "      np.savez(Data_NAME+'.npz', x=Raw_data , y=true_dag)\n",
        "\n",
        "      # 从 npz 文件中加载数据\n",
        "      data = np.load(Data_NAME+'.npz')\n",
        "      Raw_data = Tests_data['x']\n",
        "      true_dag = Tests_data['y']\n",
        "      '''\n",
        "\n",
        "    elif Data_NAME+'.csv' in Readable_File:\n",
        "      Raw_data = pd.read_csv(File_PATH+ Data_NAME+'.csv', header=0, index_col=0)\n",
        "      print(Raw_data)\n",
        "      true_dag = pd.read_csv(File_PATH+'true_graph.csv', header=0, index_col=0)\n",
        "      print(true_dag)\n",
        "############################################################\n",
        "    # Deal with Multi-dimensions Data\n",
        "    elif os.path.exists(TS_path):\n",
        "      read_Dir_TS=os.listdir(TS_path)\n",
        "      Timeseries_List_path = File_PATH+'series_list.csv'\n",
        "      Read_Timeseries = pd.read_csv(Timeseries_List_path)\n",
        "      # print(len(Read_Timeseries), len(read_Dir_TS))\n",
        "      if len(Read_Timeseries) >= len(read_Dir_TS):\n",
        "        print('INFO: Start Analyzing '+ Data_NAME + ' Time Series File!')\n",
        "        TS_List = read_Dir_TS\n",
        "      else:\n",
        "        print('INFO: Start Analyzing '+ Data_NAME + ' Time Series List!')\n",
        "        TS_List = Read_Timeseries['Series_num']\n",
        "\n",
        "      # for i, j in combinations(range(len(TS_List)), 2):\n",
        "      [i, j] = [1,2]\n",
        "      x = pd.read_csv(TS_path+TS_List[i], header=0, index_col=0)\n",
        "      y = pd.read_csv(TS_path+TS_List[j], header=0, index_col=0)\n",
        "      print(TS_List[i], TS_List[j])\n",
        "    else:\n",
        "      print('INFO: Wrong DataType!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pMuVUUbhOqA",
        "outputId": "c4270c54-2ab4-41c1-9c72-7b9b2a87f202"
      },
      "id": "-pMuVUUbhOqA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  A_10  ...  A_47  A_48  A_49  \\\n",
            "A_0                                                     ...                     \n",
            "0      1    0    0    0    0    0    4    0    1     0  ...     0     0     0   \n",
            "0      0    0    0    0    0    0    4    0    0     0  ...     3     0     0   \n",
            "0      0    0    0    0    0    3    2    0    1     0  ...     3     2     0   \n",
            "0      2    0    0    0    0    0    4    0    3     0  ...     0     2     0   \n",
            "0      4    0    0    0    0    0   11    0    4     0  ...     0     2     0   \n",
            "..   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...   ...   ...   ...   \n",
            "0      0    0    0    0    0    0    0    0    0     0  ...     3     0     0   \n",
            "0      1    0    0    0    0    0    5    0    4     0  ...     0     3     0   \n",
            "0      3    0    0    0    0    0    4    0    1     0  ...     0     2     0   \n",
            "0      1    0    0    0    0    0    1    0    1     0  ...     0     1     0   \n",
            "0      0    0    0    0    0    0    3    0    1     0  ...     0     1     0   \n",
            "\n",
            "     A_50  A_51  A_52  A_53  A_54  A_55  A_56  \n",
            "A_0                                            \n",
            "0       0     1     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       1     2     0     0     0     0     0  \n",
            "0       0     6     0     0     0     0     0  \n",
            "0       0    14     0     0     0     0     0  \n",
            "..    ...   ...   ...   ...   ...   ...   ...  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "0       0     0     0     0     0     0     0  \n",
            "\n",
            "[22589 rows x 54 columns]\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  A_7  A_8  A_9  ...  A_47  A_48  A_49  \\\n",
            "A_0     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_1     0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_2     0    0    0    0    1    1    0    0    1    1  ...     1     1     1   \n",
            "A_3     0    0    0    0    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_4     0    0    0    1    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_5     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_6     0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_7     0    1    0    1    0    0    0    0    0    1  ...     0     1     0   \n",
            "A_8     0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_9     0    0    0    1    0    0    1    0    1    0  ...     0     0     1   \n",
            "A_10    0    0    0    1    0    0    1    0    1    1  ...     1     1     0   \n",
            "A_11    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_12    0    0    0    0    0    0    1    0    0    0  ...     0     0     0   \n",
            "A_13    0    0    0    1    1    0    1    0    1    0  ...     0     1     1   \n",
            "A_14    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_15    0    0    0    1    1    0    1    0    0    0  ...     1     0     1   \n",
            "A_16    0    0    0    1    1    0    1    0    0    0  ...     1     0     0   \n",
            "A_17    0    0    0    1    0    0    1    0    1    0  ...     0     0     1   \n",
            "A_18    0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_19    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
            "A_20    0    1    0    1    0    0    1    0    1    1  ...     1     0     1   \n",
            "A_22    0    0    0    0    0    1    0    0    0    0  ...     0     1     0   \n",
            "A_23    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_24    0    0    0    1    0    0    1    0    1    0  ...     1     0     1   \n",
            "A_25    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_26    0    0    0    1    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_27    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_28    0    0    0    0    1    0    0    0    0    1  ...     0     0     0   \n",
            "A_29    0    0    0    1    0    0    1    0    0    0  ...     1     0     0   \n",
            "A_30    0    0    0    1    0    0    1    0    1    1  ...     0     1     1   \n",
            "A_31    0    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_32    0    0    0    1    0    0    1    1    1    1  ...     0     1     0   \n",
            "A_33    0    1    0    1    1    1    1    1    1    1  ...     1     1     1   \n",
            "A_35    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_36    0    0    0    1    0    0    1    1    1    1  ...     1     1     0   \n",
            "A_37    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_38    0    0    0    1    0    0    1    0    1    1  ...     1     0     0   \n",
            "A_39    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_40    0    0    0    1    0    0    1    0    1    0  ...     1     0     0   \n",
            "A_41    0    0    0    1    0    1    1    1    1    1  ...     1     1     1   \n",
            "A_42    0    0    0    1    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_43    0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_44    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_45    0    0    0    0    0    0    1    0    1    1  ...     0     1     0   \n",
            "A_46    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_47    0    0    0    1    0    0    1    0    1    1  ...     1     0     1   \n",
            "A_48    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_49    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_50    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_51    0    0    0    0    0    0    0    0    0    0  ...     0     0     0   \n",
            "A_52    0    1    0    1    1    0    1    0    0    1  ...     1     0     1   \n",
            "A_53    0    0    0    0    0    0    0    0    0    0  ...     1     0     0   \n",
            "A_54    0    0    0    1    1    0    1    0    1    0  ...     1     0     1   \n",
            "A_55    0    0    0    0    0    1    0    0    0    0  ...     0     0     0   \n",
            "A_56    1    0    0    1    0    0    0    0    0    0  ...     0     0     0   \n",
            "\n",
            "      A_50  A_51  A_52  A_53  A_54  A_55  A_56  \n",
            "A_0      0     0     0     0     0     0     0  \n",
            "A_1      1     1     0     0     0     0     0  \n",
            "A_2      1     1     1     0     1     1     0  \n",
            "A_3      0     0     0     0     0     0     0  \n",
            "A_4      0     0     0     0     0     0     0  \n",
            "A_5      0     0     0     0     0     0     0  \n",
            "A_6      0     0     0     0     0     0     0  \n",
            "A_7      0     0     0     0     0     1     0  \n",
            "A_8      0     0     0     0     0     0     0  \n",
            "A_9      1     1     0     0     0     1     0  \n",
            "A_10     0     0     0     0     0     1     0  \n",
            "A_11     0     0     0     0     0     0     0  \n",
            "A_12     0     0     0     0     0     0     0  \n",
            "A_13     1     1     0     0     0     0     0  \n",
            "A_14     0     0     0     0     0     0     0  \n",
            "A_15     0     1     0     0     0     0     0  \n",
            "A_16     0     0     0     0     0     0     0  \n",
            "A_17     0     0     0     0     0     1     0  \n",
            "A_18     0     0     0     0     0     0     0  \n",
            "A_19     1     1     0     0     0     0     0  \n",
            "A_20     1     1     0     0     0     0     0  \n",
            "A_22     0     0     0     0     0     0     0  \n",
            "A_23     0     0     0     0     0     0     0  \n",
            "A_24     1     1     0     0     0     1     0  \n",
            "A_25     0     0     0     0     0     0     0  \n",
            "A_26     1     1     0     0     0     1     0  \n",
            "A_27     0     0     0     0     0     0     0  \n",
            "A_28     0     0     0     0     0     1     0  \n",
            "A_29     0     0     0     0     0     0     0  \n",
            "A_30     0     1     0     0     0     1     0  \n",
            "A_31     0     0     0     0     0     0     0  \n",
            "A_32     1     1     0     0     0     1     0  \n",
            "A_33     1     1     1     0     1     1     0  \n",
            "A_35     0     0     0     0     0     0     0  \n",
            "A_36     1     1     0     0     0     1     0  \n",
            "A_37     0     0     0     0     0     0     0  \n",
            "A_38     1     1     0     0     0     1     0  \n",
            "A_39     0     0     0     0     0     0     0  \n",
            "A_40     1     1     0     0     0     0     0  \n",
            "A_41     1     1     0     0     0     1     0  \n",
            "A_42     1     1     0     0     0     0     0  \n",
            "A_43     0     0     0     0     0     0     0  \n",
            "A_44     0     0     0     0     0     0     0  \n",
            "A_45     1     1     0     0     0     1     0  \n",
            "A_46     0     0     0     0     0     0     0  \n",
            "A_47     1     1     0     0     0     1     0  \n",
            "A_48     0     0     0     0     0     0     0  \n",
            "A_49     0     0     0     0     0     0     0  \n",
            "A_50     1     0     0     0     0     0     0  \n",
            "A_51     0     0     0     0     0     0     0  \n",
            "A_52     1     1     0     0     0     0     0  \n",
            "A_53     0     0     0     0     0     0     0  \n",
            "A_54     0     1     0     0     0     0     0  \n",
            "A_55     0     0     0     0     0     0     0  \n",
            "A_56     0     0     0     0     0     0     0  \n",
            "\n",
            "[55 rows x 55 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
