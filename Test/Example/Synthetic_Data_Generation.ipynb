{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ANM_NCPOP_GenerateData\n",
        "* Generate the time series data from LDS with parameters: g, f_dash, proc_noise_std, obs_noise_std, T\n",
        "* Visualize the generated time series"
      ],
      "metadata": {
        "id": "5gQWZ1GduguB"
      },
      "id": "5gQWZ1GduguB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 1: Get start__\n",
        "\n",
        "* mount drive\n",
        "* set envirment\n",
        "* install packages"
      ],
      "metadata": {
        "id": "-Dt3I4ccxuw1"
      },
      "id": "-Dt3I4ccxuw1"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP/\")\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks/Test_Causality_Datasets/Real_data/Krebs_Cycle/Details_Krebs_Cycle/MetricsDAG/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTqOomJUueln",
        "outputId": "6b2b50ce-acc2-4c53-d71f-8372b16f8aa3"
      },
      "id": "jTqOomJUueln",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 2: Generate IID Time sets__"
      ],
      "metadata": {
        "id": "sA_RPz9EKbbV"
      },
      "id": "sA_RPz9EKbbV"
    },
    {
      "cell_type": "code",
      "source": [
        "from BuiltinDataSet import DAG\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import logging\n",
        "\n",
        "class ANMNCPOP_GenerateData(object):\n",
        "    '''\n",
        "    Simulate IID datasets for causal structure learning.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    W: np.ndarray\n",
        "        Weighted adjacency matrix for the target causal graph.\n",
        "    n: int\n",
        "        Number of samples for standard trainning dataset.\n",
        "    T: int\n",
        "        Number of timeseries for standard trainning dataset.\n",
        "    method: str, (linear or nonlinear), default='linear'\n",
        "        Distribution for standard trainning dataset.\n",
        "    sem_type: str\n",
        "        gauss, exp, gumbel, uniform, logistic (linear);\n",
        "        mlp, mim, gp, gp-add, quadratic (nonlinear).\n",
        "    noise_scale: float\n",
        "        Scale parameter of noise distribution in linear SEM.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, W, n=1000, T=20, method='linear',\n",
        "                 sem_type='gauss', noise_scale=1.0):\n",
        "\n",
        "        self.B = (W != 0).astype(int)\n",
        "        if method == 'linear':\n",
        "            self.XX = ANMNCPOP_GenerateData._simulate_linear_sem(\n",
        "                    W, n, T, sem_type, noise_scale)\n",
        "        elif method == 'nonlinear':\n",
        "            self.XX = ANMNCPOP_GenerateData._simulate_nonlinear_sem(\n",
        "                    W, n, T, sem_type, noise_scale)\n",
        "        logging.info('Finished synthetic dataset')\n",
        "\n",
        "    @staticmethod\n",
        "    def _simulate_linear_sem(W, n, T, sem_type, noise_scale):\n",
        "        \"\"\"\n",
        "        Simulate samples from linear SEM with specified type of noise.\n",
        "        For uniform, noise z ~ uniform(-a, a), where a = noise_scale.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        W: np.ndarray\n",
        "            [d, d] weighted adj matrix of DAG.\n",
        "        n: int\n",
        "            Number of samples, n=inf mimics population risk.\n",
        "        T: int\n",
        "        Number of timeseries for standard trainning dataset.\n",
        "        sem_type: str\n",
        "            gauss, exp, gumbel, uniform, logistic.\n",
        "        noise_scale: float\n",
        "            Scale parameter of noise distribution in linear SEM.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        XX: np.ndarray\n",
        "            [T, n, d] sample matrix, [d, d] if n and T=inf\n",
        "        \"\"\"\n",
        "        def _simulate_single_equation(X, w, scale):\n",
        "            \"\"\"X: [n, num of parents], w: [num of parents], x: [n]\"\"\"\n",
        "            if sem_type == 'gauss':\n",
        "                z = np.random.normal(scale=scale, size=T)\n",
        "                x = X @ w + z\n",
        "            elif sem_type == 'exp':\n",
        "                z = np.random.exponential(scale=scale, size=T)\n",
        "                x = X @ w + z\n",
        "            elif sem_type == 'gumbel':\n",
        "                z = np.random.gumbel(scale=scale, size=T)\n",
        "                x = X @ w + z\n",
        "            elif sem_type == 'uniform':\n",
        "                z = np.random.uniform(low=-scale, high=scale, size=T)\n",
        "                x = X @ w + z\n",
        "            elif sem_type == 'logistic':\n",
        "                x = np.random.binomial(1, sigmoid(X @ w)) * 1.0\n",
        "            else:\n",
        "                raise ValueError('Unknown sem type. In a linear model, \\\n",
        "                                 the options are as follows: gauss, exp, \\\n",
        "                                 gumbel, uniform, logistic.')\n",
        "            return x\n",
        "\n",
        "        d = W.shape[0]\n",
        "        if noise_scale is None:\n",
        "            scale_vec = np.ones(d)\n",
        "        elif np.isscalar(noise_scale):\n",
        "            scale_vec = noise_scale * np.ones(d)\n",
        "        else:\n",
        "            if len(noise_scale) != d:\n",
        "                raise ValueError('noise scale must be a scalar or has length d')\n",
        "            scale_vec = noise_scale\n",
        "        G_nx =  nx.from_numpy_array(W, create_using=nx.DiGraph)\n",
        "        if not nx.is_directed_acyclic_graph(G_nx):\n",
        "            raise ValueError('W must be a DAG')\n",
        "        if np.isinf(T):  # population risk for linear gauss SEM\n",
        "            if sem_type == 'gauss':\n",
        "                # make 1/d X'X = true cov\n",
        "                X = np.sqrt(d) * np.diag(scale_vec) @ np.linalg.inv(np.eye(d) - W)\n",
        "                return X\n",
        "            else:\n",
        "                raise ValueError('population risk not available')\n",
        "        # empirical risk\n",
        "        ordered_vertices = list(nx.topological_sort(G_nx))\n",
        "        assert len(ordered_vertices) == d\n",
        "        X = np.zeros([T, d])\n",
        "        XX = np.zeros((T, n, d))\n",
        "        for j in ordered_vertices:\n",
        "            parents = list(G_nx.predecessors(j))\n",
        "            X[:, j] = _simulate_single_equation(X[:, parents], W[parents, j], scale_vec[j])\n",
        "        for ns in range(n):\n",
        "            XX[:, ns] = X\n",
        "        return XX\n",
        "\n",
        "    @staticmethod\n",
        "    def _simulate_nonlinear_sem(W, n, T, sem_type, noise_scale):\n",
        "        \"\"\"\n",
        "        Simulate samples from nonlinear SEM.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        B: np.ndarray\n",
        "            [d, d] binary adj matrix of DAG.\n",
        "        n: int\n",
        "            Number of samples.\n",
        "        T: int\n",
        "            Number of times.\n",
        "        sem_type: str\n",
        "            mlp, mim, gp, gp-add, or quadratic.\n",
        "        noise_scale: float\n",
        "            Scale parameter of noise distribution in linear SEM.\n",
        "\n",
        "        Return\n",
        "        ------\n",
        "        XX: np.ndarray\n",
        "            [T, n, d] sample matrix\n",
        "        \"\"\"\n",
        "        if sem_type == 'quadratic':\n",
        "            return GenerateData._simulate_quad_sem(W, T, noise_scale)\n",
        "\n",
        "        def _simulate_single_equation(X, scale):\n",
        "            \"\"\"X: [n, num of parents], x: [n]\"\"\"\n",
        "            z = np.random.normal(scale=scale, size=n)\n",
        "            pa_size = X.shape[1]\n",
        "            if pa_size == 0:\n",
        "                return z\n",
        "            if sem_type == 'mlp':\n",
        "                hidden = 100\n",
        "                W1 = np.random.uniform(low=0.5, high=2.0, size=[pa_size, hidden])\n",
        "                W1[np.random.rand(*W1.shape) < 0.5] *= -1\n",
        "                W2 = np.random.uniform(low=0.5, high=2.0, size=hidden)\n",
        "                W2[np.random.rand(hidden) < 0.5] *= -1\n",
        "                x = sigmoid(X @ W1) @ W2 + z\n",
        "            elif sem_type == 'mim':\n",
        "                w1 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n",
        "                w1[np.random.rand(pa_size) < 0.5] *= -1\n",
        "                w2 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n",
        "                w2[np.random.rand(pa_size) < 0.5] *= -1\n",
        "                w3 = np.random.uniform(low=0.5, high=2.0, size=pa_size)\n",
        "                w3[np.random.rand(pa_size) < 0.5] *= -1\n",
        "                x = np.tanh(X @ w1) + np.cos(X @ w2) + np.sin(X @ w3) + z\n",
        "            elif sem_type == 'gp':\n",
        "                from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "                gp = GaussianProcessRegressor()\n",
        "                x = gp.sample_y(X, random_state=None).flatten() + z\n",
        "            elif sem_type == 'gp-add':\n",
        "                from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "                gp = GaussianProcessRegressor()\n",
        "                x = sum([gp.sample_y(X[:, i, None], random_state=None).flatten()\n",
        "                        for i in range(X.shape[1])]) + z\n",
        "            else:\n",
        "                raise ValueError('Unknown sem type. In a nonlinear model, \\\n",
        "                                 the options are as follows: mlp, mim, \\\n",
        "                                 gp, gp-add, or quadratic.')\n",
        "            return x\n",
        "\n",
        "        B = (W != 0).astype(int)\n",
        "        d = B.shape[0]\n",
        "        if noise_scale is None:\n",
        "            scale_vec = np.ones(d)\n",
        "        elif np.isscalar(noise_scale):\n",
        "            scale_vec = noise_scale * np.ones(d)\n",
        "        else:\n",
        "            if len(noise_scale) != d:\n",
        "                raise ValueError('noise scale must be a scalar or has length d')\n",
        "            scale_vec = noise_scale\n",
        "        X = np.zeros([T, d])\n",
        "        XX = np.zeros((T, n, d))\n",
        "        G_nx =  nx.from_numpy_array(B, create_using=nx.DiGraph)\n",
        "        ordered_vertices = list(nx.topological_sort(G_nx))\n",
        "        assert len(ordered_vertices) == d\n",
        "        for j in ordered_vertices:\n",
        "            parents = list(G_nx.predecessors(j))\n",
        "            X[:, j] = _simulate_single_equation(X[:, parents], scale_vec[j])\n",
        "        for ns in range(n):\n",
        "            XX[:, ns] = X\n",
        "\n",
        "        return XX\n",
        "\n"
      ],
      "metadata": {
        "id": "G60ottpWH29N"
      },
      "id": "G60ottpWH29N",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Step 3: Test_GenerateIID__"
      ],
      "metadata": {
        "id": "G4zutmN9UG7d"
      },
      "id": "G4zutmN9UG7d"
    },
    {
      "cell_type": "code",
      "source": [
        "method = 'linear'\n",
        "sem_type = 'gauss'\n",
        "num_nodes = 6\n",
        "num_edges = 15\n",
        "num_datasets = 10\n",
        "T=20\n",
        "# Weighted adjacency matrix for the target causal graph\n",
        "weighted_random_dag = DAG.erdos_renyi(n_nodes=num_nodes, n_edges=num_edges, seed=1)\n",
        "# _simulate_linear_sem(W =weighted_random_dag, n = num_datasets, sem_type = 'gauss', noise_scale=1.0)\n",
        "dataset = ANMNCPOP_GenerateData(W=weighted_random_dag, n=num_datasets, T=20, method=method, sem_type=sem_type)\n",
        "true_dag, data = dataset.B, dataset.XX\n",
        "# print(weighted_random_dag)\n",
        "print(true_dag)\n",
        "print(data.shape)\n",
        "np.save('ANMNCPOP_GenerateTimeIID.npy', data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yUOG5uTBfj-",
        "outputId": "b2c63c48-70e3-4f84-fd93-d16e79a3865f"
      },
      "id": "7yUOG5uTBfj-",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0 1 0]\n",
            " [1 0 1 1 1 1]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 1 0 1 0]\n",
            " [0 0 0 0 0 0]\n",
            " [1 0 1 0 1 0]]\n",
            "(20, 10, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Generate LDS Timesets*__"
      ],
      "metadata": {
        "id": "unFbc5fsTaZR"
      },
      "id": "unFbc5fsTaZR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaa85b05",
      "metadata": {
        "id": "aaa85b05"
      },
      "outputs": [],
      "source": [
        "from inputlds import*\n",
        "import numpy as np\n",
        "\n",
        "class DataGenerate(object):\n",
        "    \"\"\"Generator based on NCPOP Regressor\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Kozdoba, Mark and Marecek, Jakub and Tchrakian, Tigran and Mannor, Shie,\n",
        "    \"On-line learning of linear dynamical systems: Exponential forgetting in kalman filters\",\n",
        "    In Proceedings of the AAAI Conference on Artificial Intelligence, 2019\n",
        "\n",
        "    Zhou, Quan and Marecek, Jakub,\n",
        "    \"Proper Learning of Linear Dynamical Systems as a Non-Commutative Polynomial Optimisation Problem\",\n",
        "    arXiv, 2020\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(DataGenerate, self).__init__()\n",
        "\n",
        "    def data_generation(self, g, f_dash, proc_noise_std, obs_noise_std, T):\n",
        "        '''\n",
        "        Generate the T*len(f_dash) time series data from Linear dynamical system with proc_noise and obs_noise\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        g: Hidden state parameter\n",
        "        f_dash: Observation state parameter\n",
        "        proc_noise_std: Hidden state noise\n",
        "        obs_noise_std: Observation state noise\n",
        "        T: Time\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list: T*len(f_dash) list\n",
        "\n",
        "        Examples\n",
        "        --------\n",
        "        >>> from inputlds import*\n",
        "        >>> import numpy as np\n",
        "        >>> T=10\n",
        "        >>> g = np.matrix([[0.8,0,0],[0,0.9,0],[0,0,0.1]])\n",
        "        >>> f_dash = np.matrix([[1.0,0.5,0.3],[0.1,0.1,0.1]])\n",
        "        >>> proc_noise_std=0.01\n",
        "        >>> obs_noise_std=0.01\n",
        "        >>> ANM_NCPOP_DataGenerate().data_generation(g,f_dash,proc_noise_std,obs_noise_std,T)\n",
        "\n",
        "        '''\n",
        "\n",
        "        n=len(g)\n",
        "        m=len(f_dash)\n",
        "        ds1 = dynamical_system(g,np.zeros((n,m)),f_dash,np.zeros((m,m)),\n",
        "                process_noise='gaussian',\n",
        "                observation_noise='gaussian',\n",
        "                process_noise_std=proc_noise_std,\n",
        "                observation_noise_std=obs_noise_std)\n",
        "        inputs = np.zeros((m,T))\n",
        "        h0=np.ones(ds1.d) # initial state\n",
        "        ds1.solve(h0=h0, inputs=inputs, T=T)\n",
        "        return np.asarray(ds1.outputs).reshape(T,m).tolist()\n",
        "\n",
        "\n",
        "    def data_generation_dim(self, m, n, proc_noise_std,obs_noise_std,T):\n",
        "        '''\n",
        "        Generate the T*m time series data from Linear dynamical system with proc_noise and obs_noise\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n: Hidden state dimension\n",
        "        m: Observation state dimension\n",
        "        proc_noise_std: Hidden state noise\n",
        "        obs_noise_std: Observation state noise\n",
        "        T: Time\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list:  T*m list\n",
        "\n",
        "        Examples\n",
        "        --------\n",
        "        >>> from inputlds import*\n",
        "        >>> import numpy as np\n",
        "        >>> n=3\n",
        "        >>> m=2\n",
        "        >>> T=20\n",
        "        >>> proc_noise_std=0.01\n",
        "        >>> obs_noise_std=0.01\n",
        "        >>> ANM_NCPOP_DataGenerate().data_generation(m, n, proc_noise_std, obs_noise_std, T)\n",
        "        '''\n",
        "\n",
        "        g = np.random.randint(0, 2, (n,n))\n",
        "        f_dash = np.random.randint(0, 2, (m,n))\n",
        "        ds1 = dynamical_system(g,np.zeros((n,m)),f_dash,np.zeros((m,m)),\n",
        "                process_noise='gaussian',\n",
        "                observation_noise='gaussian',\n",
        "                process_noise_std=proc_noise_std,\n",
        "                observation_noise_std=obs_noise_std)\n",
        "        inputs = np.zeros((m,T))\n",
        "        h0=np.ones(ds1.d) # initial state\n",
        "        ds1.solve(h0=h0, inputs=inputs, T=T)\n",
        "        return np.asarray(ds1.outputs).reshape(T,m).tolist()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Data Generation class"
      ],
      "metadata": {
        "id": "u3m9eeel_sEw"
      },
      "id": "u3m9eeel_sEw"
    },
    {
      "cell_type": "code",
      "source": [
        "from inputlds import*\n",
        "import numpy as np\n",
        "T=10\n",
        "g = np.matrix([[0.8,0,0],[0,0.9,0],[0,0,0.1]])\n",
        "f_dash = np.matrix([[1.0,0.5,0.3],[0.1,0.1,0.1]])\n",
        "proc_noise_std=0.01\n",
        "obs_noise_std=0.01\n",
        "my_array = DataGenerate().data_generation(g,f_dash,proc_noise_std,obs_noise_std,T)\n",
        "my_array\n",
        "df = pd.DataFrame(my_array)\n",
        "df.to_csv('lds_data.csv', index=False, header=['col1','col2'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWTC2X612H0a",
        "outputId": "87adbf58-0b20-4078-d1e7-04a8ca8a9865"
      },
      "id": "SWTC2X612H0a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1.2747847483078838, 0.19594359308281661],\n",
              " [1.0454801175607462, 0.14571383137678165],\n",
              " [0.859624443447321, 0.11136022132381274],\n",
              " [0.7522937590854241, 0.10262556381907625],\n",
              " [0.6384014976018458, 0.10143255711088069],\n",
              " [0.4983139644085479, 0.0856117047216572],\n",
              " [0.4550613076727763, 0.0647366171990469],\n",
              " [0.3835754692208594, 0.04253721891070902],\n",
              " [0.33822278060577826, 0.044561053378408044],\n",
              " [0.2729466435786535, 0.048692423439118775]]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inputlds import*\n",
        "import numpy as np\n",
        "n=3\n",
        "m=2\n",
        "T=10\n",
        "proc_noise_std=0.01\n",
        "obs_noise_std=0.01\n",
        "DataGenerate().data_generation_dim(m,n,proc_noise_std,obs_noise_std,T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUf1dCa-4LIT",
        "outputId": "8eb3f7f5-9538-4edd-f0ab-f52c2691a9dc"
      },
      "id": "JUf1dCa-4LIT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0014143954478208506, 3.00304475804575],\n",
              " [-0.00860099022621434, 3.966124614146327],\n",
              " [-0.007635469446289098, 4.934599419454813],\n",
              " [0.01215965486252258, 5.9442183250672675],\n",
              " [0.010714011287707595, 6.904107192953694],\n",
              " [-0.007857632146403469, 7.87991343574115],\n",
              " [0.018804761747808166, 8.92670669775614],\n",
              " [-0.0023952497348262093, 9.929117447988316],\n",
              " [0.009015414863869095, 10.938080588526418],\n",
              " [0.009820536471639578, 11.921019820155285]]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
