{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#__ANM-NCPOP__\n",
        "Define a function for solving the NCPO problems with given standard deviations of process noise and observtion noise, length of  estimation data and required relaxation level.\n",
        "\n",
        "* Generate the artificial data or standardized observational data.\n",
        "* Learn the Causal Structure beneath the observation data.\n",
        "* Visualize the comparison of estimated/true graphs using a heat map.\n",
        "* Calculate Metrics.\n",
        "* Demonstrate the performance of method ANM-NCPOP in a heatmap.\n",
        "\n",
        "**Flow**\n",
        "\n",
        "Class NCPOLR: Functions generate_operators, estimate\n",
        "\n",
        "Class ANM_NCPO: Functions learn, ANMNCPO_fitness\n",
        "\n",
        "                                                      [Input raw data]\n",
        "                                                              ↓\n",
        "                                                    <generate_operators>\n",
        "                                                              |\n",
        "                                                              | Generate Operators\n",
        "                                                              ↓\n",
        "                                                  <estimate or estimate2>\n",
        "                                                              |\n",
        "                                                              | Solve NCPOLR problem\n",
        "                                                              ↓\n",
        "                        [Output DAG] <--- <learn> <--- <ANMNCPO_fitness>"
      ],
      "metadata": {
        "id": "kq1OSo5X0whe"
      },
      "id": "kq1OSo5X0whe"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP/Causal_Models_Learning/Test/\")\n",
        "# os.chdir(\"/content/drive/MyDrive/Colab Notebooks/NCPOP/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxG01ITDDrxJ",
        "outputId": "b8ac7430-1860-46a3-e5e7-338b86d1ef61"
      },
      "id": "QxG01ITDDrxJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTHONPATH=\"$PYTHONPATH:/content/drive/MyDrive/Colab Notebooks/NCPOP-Colab Notebooks-data\"\n",
        "import os\n",
        "os.environ['MOSEKLM_LICENSE_FILE']=\"/content/drive/MyDrive/Colab Notebooks/NCPOP/\""
      ],
      "metadata": {
        "id": "YvsgA49ewu23"
      },
      "id": "YvsgA49ewu23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a349920",
        "outputId": "74285e07-fedd-42e1-b01e-f745446f59c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mosek\n",
            "  Downloading Mosek-10.2.1-cp37-abi3-manylinux2014_x86_64.whl (15.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mosek) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mosek, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed mosek-10.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting ncpol2sdpa\n",
            "  Downloading ncpol2sdpa-1.12.2.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sympy>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from ncpol2sdpa) (1.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ncpol2sdpa) (1.25.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=0.7.2->ncpol2sdpa) (1.3.0)\n",
            "Building wheels for collected packages: ncpol2sdpa\n",
            "  Building wheel for ncpol2sdpa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ncpol2sdpa: filename=ncpol2sdpa-1.12.2-py3-none-any.whl size=70795 sha256=10d6308011b83bbe8497a95c799d5db818ac0dc36170203b4c6dbd5cfc9cc38b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/d7/fe/ab61f3bf30a350feab3bb4dccd63932d56cbbd32b9ec0d94fa\n",
            "Successfully built ncpol2sdpa\n",
            "Installing collected packages: ncpol2sdpa\n",
            "Successfully installed ncpol2sdpa-1.12.2\n",
            "Collecting gcastle==1.0.3rc2\n",
            "  Downloading gcastle-1.0.3rc2-py3-none-any.whl (187 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (3.7.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (3.3)\n",
            "Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from gcastle==1.0.3rc2) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.2->gcastle==1.0.3rc2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->gcastle==1.0.3rc2) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->gcastle==1.0.3rc2) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.1->gcastle==1.0.3rc2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.1->gcastle==1.0.3rc2) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.2->gcastle==1.0.3rc2) (1.16.0)\n",
            "Installing collected packages: gcastle\n",
            "Successfully installed gcastle-1.0.3rc2\n"
          ]
        }
      ],
      "source": [
        "### for colab ###\n",
        "# To execute the notebook directly in colab make sure your MOSEK license file is in one the locations\n",
        "#\n",
        "# /content/mosek.lic   or   /root/mosek/mosek.lic\n",
        "#\n",
        "# inside this notebook's internal filesystem.\n",
        "# Install MOSEK and ncpol2sdpa if not already installed\n",
        "!pip install mosek torch\n",
        "!pip install ncpol2sdpa\n",
        "# !pip install networkx\n",
        "!pip install gcastle==1.0.3rc2"
      ],
      "id": "8a349920"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from castle.common import GraphDAG\n",
        "from castle.metrics import MetricsDAG\n",
        "from sklearn.preprocessing import scale\n",
        "from itertools import combinations\n",
        "from castle.common import BaseLearner, Tensor\n",
        "from castle.common.independence_tests import hsic_test\n",
        "from ncpol2sdpa import*\n",
        "\n",
        "\n",
        "\n",
        "class Anm_ncpop_test(object):\n",
        "    '''\n",
        "    A class for simulating (causal) DAG, where the true DAG is a weighed/binary adjacency matrix based on ground truth.\n",
        "\n",
        "    Parameters\n",
        "    ------------------------------------------------------------------------------------------------\n",
        "    File_PATH: str\n",
        "            Read file path\n",
        "    File_NAME: str\n",
        "            Read data name\n",
        "    File_PATH_Summary_Datails: str\n",
        "            Save file path\n",
        "    datasize: series\n",
        "\n",
        "    Timesize: series\n",
        "\n",
        "    Returns\n",
        "    ------------------------------------------------------------------------------------------------\n",
        "    Metrics DAG: np.matrix\n",
        "            heatmap between estimate DAG matrix and true DAG\n",
        "    Casaul Metrics: np.matrix\n",
        "            estimate DAG matrix\n",
        "    Summary scores table: pd.dataframe\n",
        "           col_names = ['Datasize','Timesets', 'Duration', 'fdr', 'tpr', 'fpr', 'shd', 'nnz', 'precision', 'recall', 'F1', 'gscore'])\n",
        "    Summary table: pd.dataframe\n",
        "           col_names = ['DataSize', 'Timesets', 'F1_Score', 'Duration']\n",
        "\n",
        "    Examples\n",
        "    -------------------------------------------------------------------------------------------------\n",
        "    >>> # filename = LinearSEM_GaussNoise\n",
        "    >>> # data_name = LinearSEM_GaussNoise_6Nodes_15Edges_TS\n",
        "    >>> # save_name = LinearSEM_GaussNoise_6Nodes_15Edges_TS_15Datasize_5Timesets\n",
        "\n",
        "    >>> datasize = range(5, 40, 5)\n",
        "    >>> Timesize = range(3, 6, 1)\n",
        "    >>> File_PATH_Base = 'Test/Examples/Test_data/'\n",
        "    >>> File_PATH_Summary_Datails = 'Test/Examples/Test_data/Summary'\n",
        "    >>> File_PATH = File_PATH\n",
        "    >>> Data_NAME = 'LinearSEM_GaussNoise_6Nodes_15Edges_TS.npz'\n",
        "    >>> # Data_NAME = 'Krebs_Cycle_16Nodes_43Edges_TS.npz'\n",
        "    >>> rt = Anm_ncpop_test(File_PATH_Base, Data_NAME, File_PATH_Summary_Datails, datasize, Timesize)\n",
        "    >>> rt.Ancpop()\n",
        "\n",
        "    '''\n",
        "    def __init__(self, File_PATH = None, Datasize=range(5, 40, 5), Timeset= range(3, 6, 1)):\n",
        "        self.File_PATH = File_PATH\n",
        "        self.Datasize =  Datasize\n",
        "        # self.Datasize_num = len(self.Datasize)\n",
        "        self.Timeset = Timeset\n",
        "        # self.Timesize_num = len(self.Timesize)\n",
        "        self.filename = filename\n",
        "        # re.split(\"_\", re.split(\"/\", self.File_PATH_Datasets)[-1])[0]\n",
        "\n",
        "\n",
        "    def Ancpop(self):\n",
        "        ################################################  Create Ground Tier Folders #############################################\n",
        "        self.File_PATH_Base = self.File_PATH +'Result_'+ self.filename +'/'\n",
        "        if not os.path.exists(self.File_PATH_Base):\n",
        "            os.makedirs(self.File_PATH_Base)\n",
        "        print('ANM-NCPOP INFO: Created Basement'+ ' File!')\n",
        "\n",
        "        ################################################  Create First Tier Folders #############################################\n",
        "        self.File_PATH_Summary = self.File_PATH_Base + 'Summary_'+ self.filename +'/'\n",
        "        if not os.path.exists(self.File_PATH_Summary):\n",
        "            os.makedirs(self.File_PATH_Summary)\n",
        "        print('ANM-NCPOP INFO: Created Summary'+ ' File!')\n",
        "\n",
        "        self.File_PATH_Datasets = self.File_PATH_Base + 'Datasets_'+ self.filename +'/'\n",
        "        if not os.path.exists(self.File_PATH_Datasets):\n",
        "            os.makedirs(self.File_PATH_Datasets)\n",
        "            dt = Real_Data_Standardization(self.File_PATH, self.filename)\n",
        "            dt.standardize_data()\n",
        "\n",
        "        print('ANM-NCPOP INFO: Created Datasets' + ' File!')\n",
        "\n",
        "        ################################################  Create Second Tier Folders #############################################\n",
        "        self.File_PATH_Summary_Datails = self.File_PATH_Summary + 'Summary_Datails_'+self.filename +'/'\n",
        "        self.File_PATH_MetricsDAG = self.File_PATH_Summary +'MetricsDAG_'+self.filename +'/'\n",
        "        if not os.path.exists(self.File_PATH_Summary_Datails):\n",
        "            os.makedirs(self.File_PATH_Summary_Datails)\n",
        "        print('ANM-NCPOP INFO: Created Summary_Datails'+ ' File!')\n",
        "        if not os.path.exists(self.File_PATH_MetricsDAG):\n",
        "            os.makedirs(self.File_PATH_MetricsDAG)\n",
        "        print('ANM-NCPOP INFO: Created MetricsDAG'+ ' File!')\n",
        "\n",
        "        ################################################  Analyzing Data under Datasets ###############################\n",
        "        tqdm=os.listdir(self.File_PATH_Summary_Datails)\n",
        "        read_Dir=os.listdir(self.File_PATH_Datasets)\n",
        "        while len(tqdm)!= len(read_Dir):\n",
        "            for data_name in read_Dir:\n",
        "                # print(file_f)\n",
        "                filename = utils.saveName_transfer_to_filename(data_name)\n",
        "\n",
        "                df_F1 = self.File_PATH_Summary_Datails + 'F1_'+ data_name +'.csv'\n",
        "                if not os.path.exists(df_F1):\n",
        "                    Rawdata = np.load(self.File_PATH_Datasets+data_name)\n",
        "                    self.Ancpop_estimate(self, Rawdata, data_name)\n",
        "                print('ANM-NCPOP INFO: Finished '+ data_name+'Analyzing!')\n",
        "        print('ANM NCPOP INFO: Finished simulations!')\n",
        "\n",
        "    @staticmethod\n",
        "    def Ancpop_estimate(self, Rawdata, data_name):\n",
        "        Raw_data = Rawdata['x']\n",
        "        true_dag = Rawdata['y']\n",
        "        duration_anm_ncpop = []\n",
        "        f1_anm_ncpop = []\n",
        "        df = pd.DataFrame(columns=['Datasize','Timesets', 'Duration', 'fdr', 'tpr', 'fpr', 'shd', 'nnz', 'precision', 'recall', 'F1', 'gscore'])\n",
        "        for i in self.Datasize:\n",
        "            for j in self.Timeset:\n",
        "                data = Raw_data[:, :i, :j]\n",
        "                t_start = time.time()\n",
        "                # Test ANM-NCPOP\n",
        "                anmNCPO = ANM_NCPO(alpha=0.05)\n",
        "                anmNCPO.learn(data = data)\n",
        "                # Save estimate causal_matrix\n",
        "                save_name = data_name+'_' + str(i) + 'Datasize_'+str(j) +'Timesets'\n",
        "                pd.DataFrame(anmNCPO.causal_matrix).to_csv(self.File_PATH_MetricsDAG + save_name+'.csv',index=False)\n",
        "\n",
        "                # Plot predict_dag and true_dag\n",
        "                GraphDAG(anmNCPO.causal_matrix, true_dag, show=False, save_name = self.File_PATH_MetricsDAG + save_name+'.png')\n",
        "\n",
        "                # Save met.metrics\n",
        "                met = MetricsDAG(anmNCPO.causal_matrix, true_dag)\n",
        "                dict1 = {'Datasize':i, 'Timesets':j, 'Duration':time.time()-t_start}\n",
        "                dict2 = met.metrics\n",
        "                dict = {**dict1, **dict2}\n",
        "                df = pd.concat([df, pd.DataFrame([dict])])\n",
        "                if math.isnan(float(met.metrics['F1'])):\n",
        "                    f1_anm_ncpop.append(0.2)\n",
        "                else:\n",
        "                    f1_anm_ncpop.append(met.metrics['F1'])\n",
        "                print('ANM-NCPOP INFO: ' + save_name +' is done!'+'F1 Score is'+ str(met.metrics['F1'])+'.')\n",
        "                print('ANM-NCPOP INFO: Time Duration is '+ str(time.time()-t_start))\n",
        "                duration_anm_ncpop.append(time.time()-t_start)\n",
        "        df.to_csv(self.File_PATH_MetricsDAG + 'Scores_'+data_name+'.csv', index=False)\n",
        "        df_F1 = pd.DataFrame({\"DataSize\":self.Datasize, \"Timesets\":self.Timesets, 'F1_Score':f1_anm_ncpop, 'Duration':duration_anm_ncpop})\n",
        "        df_F1.to_csv(self.File_PATH_Summary_Datails + 'F1_'+data_name+'.csv',index=False)\n",
        "        return df_F1\n",
        "\n",
        "class NCPOLR(object):\n",
        "    \"\"\"Estimator based on NCPOP Regressor\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Quan Zhou https://github.com/Quan-Zhou/Proper-Learning-of-LDS/blob/master/ncpop/functions.py\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NCPOLR, self).__init__()\n",
        "\n",
        "\n",
        "    def generate_operators(name, n_vars=1, hermitian=None, commutative=False):\n",
        "        \"\"\"Generates a number of commutative or noncommutative operators\n",
        "\n",
        "        :param name: The prefix in the symbolic representation of the noncommuting\n",
        "                    variables. This will be suffixed by a number from 0 to\n",
        "                    n_vars-1 if n_vars > 1.\n",
        "        :type name: str.\n",
        "        :param n_vars: The number of variables.\n",
        "        :type n_vars: int.\n",
        "        :param hermitian: Optional parameter to request Hermitian variables .\n",
        "        :type hermitian: bool.\n",
        "        :param commutative: Optional parameter to request commutative variables.\n",
        "                            Commutative variables are Hermitian by default.\n",
        "        :type commutative: bool.\n",
        "\n",
        "        :returns: list of :class:`sympy.physics.quantum.operator.Operator` or\n",
        "                  :class:`sympy.physics.quantum.operator.HermitianOperator`\n",
        "                  variables\n",
        "\n",
        "        :Example:\n",
        "\n",
        "        >>> generate_variables('y', 2, commutative=True)\n",
        "        ￼[y0, y1]\n",
        "        \"\"\"\n",
        "\n",
        "        variables = []\n",
        "        for i in range(n_vars):\n",
        "            if n_vars > 1:\n",
        "                var_name = '%s%s' % (name, i)\n",
        "            else:\n",
        "                var_name = '%s' % name\n",
        "            if hermitian is not None and hermitian:\n",
        "                variables.append(HermitianOperator(var_name))\n",
        "            else:\n",
        "                variables.append(Operator(var_name))\n",
        "            variables[-1].is_commutative = commutative\n",
        "        return variables\n",
        "\n",
        "    def estimate(self, X, Y):\n",
        "        \"\"\"Fit Estimator based on NCPOP Regressor model and predict y or produce residuals.\n",
        "        The module converts a noncommutative optimization problem provided in SymPy\n",
        "        format to an SDPA semidefinite programming problem.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array\n",
        "            Variable seen as cause\n",
        "        Y: array\n",
        "            Variable seen as effect\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_predict: array\n",
        "            regression predict values of y or residuals\n",
        "        \"\"\"\n",
        "\n",
        "        T = len(Y)\n",
        "        level = 1\n",
        "\n",
        "        # Decision Variables\n",
        "        G = generate_operators(\"G\", n_vars=1, hermitian=True, commutative=False)[0]\n",
        "        f = generate_operators(\"f\", n_vars=T, hermitian=True, commutative=False)\n",
        "        n = generate_operators(\"m\", n_vars=T, hermitian=True, commutative=False)\n",
        "        p = generate_operators(\"p\", n_vars=T, hermitian=True, commutative=False)\n",
        "\n",
        "        # Objective\n",
        "        obj = sum((Y[i]-f[i])**2 for i in range(T)) + 0.00005*sum(p[i] for i in range(T))\n",
        "\n",
        "        # Constraints\n",
        "        ine1 = [f[i] - G*X[i] - n[i] for i in range(T)]\n",
        "        ine2 = [-f[i] + G*X[i] + n[i] for i in range(T)]\n",
        "        ine3 = [p[i]-n[i] for i in range(T)]\n",
        "        ine4 = [p[i]+n[i] for i in range(T)]\n",
        "        ines = ine1+ine2+ine3+ine4\n",
        "\n",
        "        # Solve the NCPO\n",
        "        sdp = SdpRelaxation(variables = flatten([G,f,n,p]),verbose = 1)\n",
        "        sdp.get_relaxation(level, objective=obj, inequalities=ines)\n",
        "        sdp.solve(solver='mosek')\n",
        "        #sdp.solve(solver='sdpa', solverparameters={\"executable\":\"sdpa_gmp\",\"executable\": \"C:/Users/zhouq/Documents/sdpa7-windows/sdpa.exe\"})\n",
        "        print(sdp.primal, sdp.dual, sdp.status)\n",
        "\n",
        "        if(sdp.status != 'infeasible'):\n",
        "            print('ok.')\n",
        "            est_noise = []\n",
        "            for i in range(T):\n",
        "                est_noise.append(sdp[n[i]])\n",
        "            print(est_noise)\n",
        "            return est_noise\n",
        "        else:\n",
        "            print('Cannot find feasible solution.')\n",
        "            return\n",
        "\n",
        "    def estimate2(self, X, Y):\n",
        "        \"\"\"Fit Estimator based on NCPOP Regressor model and predict y or produce residuals.\n",
        "        The module converts a noncommutative optimization problem provided in SymPy\n",
        "        format to an SDPA semidefinite programming problem.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Y: array\n",
        "            Variable seen as effect\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_predict: array\n",
        "            regression predict values of y or residuals\n",
        "        \"\"\"\n",
        "        Y = np.transpose(Y)\n",
        "        T = len(Y)-1\n",
        "        level = 1\n",
        "\n",
        "\n",
        "        # Decision Variables\n",
        "        G = generate_operators(\"G\", n_vars=1, hermitian=True, commutative=False)[0]\n",
        "        Fdash = generate_operators(\"Fdash\", n_vars=1, hermitian=True, commutative=False)[0]\n",
        "        # m = generate_operators(\"m\", n_vars=T+1, hermitian=True, commutative=False)\n",
        "        q = generate_operators(\"q\", n_vars=T, hermitian=True, commutative=False)\n",
        "        p = generate_operators(\"p\", n_vars=T, hermitian=True, commutative=False)\n",
        "        f = generate_operators(\"f\", n_vars=T, hermitian=True, commutative=False)\n",
        "\n",
        "        # Objective\n",
        "        obj = sum((Y[i]-f[i])**2 for i in range(T)) + 0.001*sum(p[i]**2 for i in range(T)) + 0.0005*sum(q[i]**2 for i in range(T))\n",
        "\n",
        "        #c1*sum(p[i]**2 for i in range(T)) + c2*sum(q[i]**2 for i in range(T))\n",
        "\n",
        "        # Constraints\n",
        "        ine1 = [f[i] - Fdash*X[i+1] - p[i] for i in range(T)]\n",
        "        ine2 = [-f[i] + Fdash*X[i+1] + p[i] for i in range(T)]\n",
        "        ine3 = [X[i+1] - G*X[i] - q[i] for i in range(T)]\n",
        "        ine4 = [-X[i+1] + G*X[i] + q[i] for i in range(T)]\n",
        "        #ine5 = [(Y[i]-f[i])**2 for i in range(T)]\n",
        "        ines = ine1+ine2+ine3+ine4 #+ine5\n",
        "\n",
        "        # Solve the NCPO\n",
        "        sdp = SdpRelaxation(variables = flatten([G,Fdash,f,p,q]),verbose = 1)\n",
        "        sdp.get_relaxation(level, objective=obj, inequalities=ines)\n",
        "        sdp.solve(solver='mosek')\n",
        "\n",
        "        #sdp.solve(solver='sdpa', solverparameters={\"executable\":\"sdpa_gmp\",\"executable\": \"C:/Users/zhouq/Documents/sdpa7-windows/sdpa.exe\"})\n",
        "        print(sdp.primal, sdp.dual, sdp.status)\n",
        "\n",
        "        if(sdp.status != 'infeasible'):\n",
        "            print('ok.')\n",
        "            est_noise = []\n",
        "            for i in range(T):\n",
        "                est_noise.append(sdp[p[i]])\n",
        "            print(est_noise)\n",
        "            return est_noise, X[1:]\n",
        "        else:\n",
        "            print('Cannot find feasible solution.')\n",
        "            return\n",
        "\n",
        "\n",
        "class ANM_NCPO(BaseLearner):\n",
        "    \"\"\"\n",
        "    Nonlinear causal discovery with additive noise models\n",
        "\n",
        "    Use Estimator based on NCPOP Regressor and independent Gaussian noise,\n",
        "    For the independence test, we implemented the HSIC with a Gaussian kernel,\n",
        "    where we used the gamma distribution as an approximation for the\n",
        "    distribution of the HSIC under the null hypothesis of independence\n",
        "    in order to calculate the p-value of the test result.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Hoyer, Patrik O and Janzing, Dominik and Mooij, Joris M and Peters,\n",
        "    Jonas and Schölkopf, Bernhard,\n",
        "    \"Nonlinear causal discovery with additive noise models\", NIPS 2009\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float, default 0.05\n",
        "        significance level be used to compute threshold\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    causal_matrix : array like shape of (n_features, n_features)\n",
        "        Learned causal structure matrix.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=0.05):\n",
        "        super(ANM_NCPO, self).__init__()\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def learn(self, data, columns=None, regressor=NCPOLR(),test_method=hsic_test, **kwargs):\n",
        "        \"\"\"Set up and run the ANM_NCPOP algorithm.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: numpy.ndarray or Tensor\n",
        "            Training data.\n",
        "        columns : Index or array-like\n",
        "            Column labels to use for resulting tensor. Will default to\n",
        "            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n",
        "        regressor: Class\n",
        "            Nonlinear regression estimator, if not provided, it is NCPOLR.\n",
        "            If user defined, must implement `estimate` self.method. such as :\n",
        "                `regressor.estimate(x, y)`\n",
        "        test_method: callable, default test_method\n",
        "            independence test self.method, if not provided, it is HSIC.\n",
        "            If user defined, must accept three arguments--x, y and keyword\n",
        "            argument--alpha. such as :\n",
        "                `test_method(x, y, alpha=0.05)`\n",
        "        \"\"\"\n",
        "\n",
        "        self.regressor = regressor\n",
        "\n",
        "        # create learning model and ground truth model\n",
        "        data = Tensor(data, columns=columns)\n",
        "\n",
        "        node_num = data.shape[0]\n",
        "        self.causal_matrix = Tensor(np.zeros((node_num, node_num)))\n",
        "\n",
        "        for i, j in combinations(range(node_num), 2):\n",
        "            x = data[i, :, :]\n",
        "            y = data[j, :, :]\n",
        "            xx = x.reshape(-1,1)\n",
        "            yy = y.reshape(-1,1)\n",
        "\n",
        "            flag = test_method(xx, yy, alpha=self.alpha)\n",
        "            if flag == 1:\n",
        "                continue\n",
        "            # test x-->y\n",
        "            flag = self.ANMNCPO_fitness(x, y, regressor = regressor, test_method=test_method)\n",
        "            if flag:\n",
        "                self.causal_matrix[i, j] = 1\n",
        "            # test y-->x\n",
        "            flag = self.ANMNCPO_fitness(y, x, regressor = regressor, test_method=test_method)\n",
        "            if flag:\n",
        "                self.causal_matrix[j, i] = 1\n",
        "\n",
        "    def ANMNCPO_fitness(self, x, y, regressor=NCPOLR(), test_method=hsic_test):\n",
        "        \"\"\"Compute the fitness score of the ANM_NCPOP Regression model in the x->y direction.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x: array\n",
        "            Variable seen as cause\n",
        "        y: array\n",
        "            Variable seen as effect\n",
        "        regressor: Class\n",
        "            Nonlinear regression estimator, if not provided, it is NCPOP.\n",
        "            If user defined, must implement `estimate` self.method. such as :\n",
        "                `regressor.estimate(x, y)`\n",
        "        test_method: callable, default test_method\n",
        "            independence test self.method, if not provided, it is HSIC.\n",
        "            If user defined, must accept three arguments--x, y and keyword\n",
        "            argument--alpha. such as :\n",
        "                `test_method(x, y, alpha=0.05)`\n",
        "        Returns\n",
        "        -------\n",
        "        out: int, 0 or 1\n",
        "            If 1, residuals n is independent of x, then accept x --> y\n",
        "            If 0, residuals n is not independent of x, then reject x --> y\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        x = scale(x).reshape(-1)\n",
        "        y = scale(y).reshape(-1)\n",
        "\n",
        "        ncpop_res = regressor.estimate(x, y)\n",
        "        print(x)\n",
        "        print(y)\n",
        "\n",
        "        flag = test_method(np.asarray(ncpop_res[0]).reshape((-1, 1)), np.asarray(ncpop_res[1]).reshape((-1, 1)), alpha=self.alpha)\n",
        "\n",
        "        print(flag)\n",
        "\n",
        "        return flag\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hP6jvLLn44CT"
      },
      "id": "hP6jvLLn44CT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "ey3T5UNqHAzf"
      },
      "id": "ey3T5UNqHAzf"
    },
    {
      "cell_type": "code",
      "source": [
        "datasize = range(5, 40, 5)\n",
        "Timesize = range(3, 6, 1)\n",
        "# Krebs_Cycle\n",
        "File_PATH = \"../Test/Datasets/Synthetic datasets/Krebs_Cycle/\"\n",
        "rt = Anm_ncpop_test(File_PATH, datasize, Timesize)\n",
        "rt.Ancpop()"
      ],
      "metadata": {
        "id": "gwdJDQruzdkB"
      },
      "id": "gwdJDQruzdkB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
